{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvpath = Path('yolo_bottom_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csvpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:,:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>T1_1</th>\n",
       "      <th>T1_2</th>\n",
       "      <th>T2_1</th>\n",
       "      <th>T2_2</th>\n",
       "      <th>T3_1</th>\n",
       "      <th>T3_2</th>\n",
       "      <th>H1_1</th>\n",
       "      <th>H1_2</th>\n",
       "      <th>H2_1</th>\n",
       "      <th>H2_2</th>\n",
       "      <th>H3_1</th>\n",
       "      <th>H3_2</th>\n",
       "      <th>hand</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mike_marshall_999</td>\n",
       "      <td>0.500723</td>\n",
       "      <td>0.019169</td>\n",
       "      <td>0.096098</td>\n",
       "      <td>0.576677</td>\n",
       "      <td>0.379335</td>\n",
       "      <td>0.605431</td>\n",
       "      <td>0.413295</td>\n",
       "      <td>0.137380</td>\n",
       "      <td>0.497110</td>\n",
       "      <td>0.715655</td>\n",
       "      <td>0.734827</td>\n",
       "      <td>0.645367</td>\n",
       "      <td>R</td>\n",
       "      <td>196</td>\n",
       "      <td>215</td>\n",
       "      <td>0.2702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfonso_soriano_998</td>\n",
       "      <td>0.526171</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.055096</td>\n",
       "      <td>0.237219</td>\n",
       "      <td>0.292011</td>\n",
       "      <td>0.388037</td>\n",
       "      <td>0.365014</td>\n",
       "      <td>0.171779</td>\n",
       "      <td>0.436639</td>\n",
       "      <td>0.527607</td>\n",
       "      <td>0.630165</td>\n",
       "      <td>0.514315</td>\n",
       "      <td>R</td>\n",
       "      <td>185</td>\n",
       "      <td>195</td>\n",
       "      <td>0.2703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jody_reed_997</td>\n",
       "      <td>0.464928</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.079137</td>\n",
       "      <td>0.461640</td>\n",
       "      <td>0.373201</td>\n",
       "      <td>0.490079</td>\n",
       "      <td>0.438849</td>\n",
       "      <td>0.112434</td>\n",
       "      <td>0.566547</td>\n",
       "      <td>0.713624</td>\n",
       "      <td>0.872302</td>\n",
       "      <td>0.660053</td>\n",
       "      <td>R</td>\n",
       "      <td>175</td>\n",
       "      <td>170</td>\n",
       "      <td>0.2703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kevin_bass_996</td>\n",
       "      <td>0.477839</td>\n",
       "      <td>0.020161</td>\n",
       "      <td>0.931440</td>\n",
       "      <td>0.307460</td>\n",
       "      <td>0.623269</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.584488</td>\n",
       "      <td>0.099798</td>\n",
       "      <td>0.493075</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0.198061</td>\n",
       "      <td>0.521169</td>\n",
       "      <td>L</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>0.2703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jason_barlett_995</td>\n",
       "      <td>0.424769</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.348404</td>\n",
       "      <td>0.445602</td>\n",
       "      <td>0.480496</td>\n",
       "      <td>0.493056</td>\n",
       "      <td>0.097518</td>\n",
       "      <td>0.400463</td>\n",
       "      <td>0.738475</td>\n",
       "      <td>0.788194</td>\n",
       "      <td>0.731383</td>\n",
       "      <td>R</td>\n",
       "      <td>183</td>\n",
       "      <td>190</td>\n",
       "      <td>0.2703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bobby_thomson_994</td>\n",
       "      <td>0.479962</td>\n",
       "      <td>0.127743</td>\n",
       "      <td>0.229008</td>\n",
       "      <td>0.507837</td>\n",
       "      <td>0.478053</td>\n",
       "      <td>0.542320</td>\n",
       "      <td>0.485687</td>\n",
       "      <td>0.167712</td>\n",
       "      <td>0.458969</td>\n",
       "      <td>0.721787</td>\n",
       "      <td>0.743321</td>\n",
       "      <td>0.709248</td>\n",
       "      <td>R</td>\n",
       "      <td>188</td>\n",
       "      <td>180</td>\n",
       "      <td>0.2704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rube_oldring_993</td>\n",
       "      <td>0.702236</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.239837</td>\n",
       "      <td>0.382812</td>\n",
       "      <td>0.434959</td>\n",
       "      <td>0.414062</td>\n",
       "      <td>0.526423</td>\n",
       "      <td>0.213778</td>\n",
       "      <td>0.470528</td>\n",
       "      <td>0.566051</td>\n",
       "      <td>0.706301</td>\n",
       "      <td>0.529119</td>\n",
       "      <td>R</td>\n",
       "      <td>178</td>\n",
       "      <td>186</td>\n",
       "      <td>0.2704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bill_spiers_992</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.006925</td>\n",
       "      <td>0.862664</td>\n",
       "      <td>0.296399</td>\n",
       "      <td>0.702303</td>\n",
       "      <td>0.351801</td>\n",
       "      <td>0.661184</td>\n",
       "      <td>0.047784</td>\n",
       "      <td>0.541118</td>\n",
       "      <td>0.468837</td>\n",
       "      <td>0.318257</td>\n",
       "      <td>0.409280</td>\n",
       "      <td>L</td>\n",
       "      <td>188</td>\n",
       "      <td>190</td>\n",
       "      <td>0.2705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>glenallen_hill_991</td>\n",
       "      <td>0.236891</td>\n",
       "      <td>0.006631</td>\n",
       "      <td>0.324906</td>\n",
       "      <td>0.289125</td>\n",
       "      <td>0.524345</td>\n",
       "      <td>0.322944</td>\n",
       "      <td>0.432584</td>\n",
       "      <td>0.094164</td>\n",
       "      <td>0.365169</td>\n",
       "      <td>0.415119</td>\n",
       "      <td>0.571161</td>\n",
       "      <td>0.391910</td>\n",
       "      <td>R</td>\n",
       "      <td>190</td>\n",
       "      <td>210</td>\n",
       "      <td>0.2705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>terry_steinbach_990</td>\n",
       "      <td>0.298817</td>\n",
       "      <td>0.007229</td>\n",
       "      <td>0.139053</td>\n",
       "      <td>0.219880</td>\n",
       "      <td>0.323225</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.378698</td>\n",
       "      <td>0.056024</td>\n",
       "      <td>0.434911</td>\n",
       "      <td>0.490964</td>\n",
       "      <td>0.695266</td>\n",
       "      <td>0.444578</td>\n",
       "      <td>R</td>\n",
       "      <td>185</td>\n",
       "      <td>195</td>\n",
       "      <td>0.2706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cory_hart_989</td>\n",
       "      <td>0.467470</td>\n",
       "      <td>0.035965</td>\n",
       "      <td>0.109639</td>\n",
       "      <td>0.359649</td>\n",
       "      <td>0.357831</td>\n",
       "      <td>0.419737</td>\n",
       "      <td>0.392771</td>\n",
       "      <td>0.160965</td>\n",
       "      <td>0.362651</td>\n",
       "      <td>0.535088</td>\n",
       "      <td>0.618675</td>\n",
       "      <td>0.501316</td>\n",
       "      <td>R</td>\n",
       "      <td>198</td>\n",
       "      <td>240</td>\n",
       "      <td>0.2706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tino_martiniez_988</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.835069</td>\n",
       "      <td>0.297000</td>\n",
       "      <td>0.605035</td>\n",
       "      <td>0.391000</td>\n",
       "      <td>0.625868</td>\n",
       "      <td>0.178000</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.542000</td>\n",
       "      <td>0.392361</td>\n",
       "      <td>0.517500</td>\n",
       "      <td>L</td>\n",
       "      <td>188</td>\n",
       "      <td>205</td>\n",
       "      <td>0.2707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>omar_infante_987</td>\n",
       "      <td>0.614621</td>\n",
       "      <td>0.113071</td>\n",
       "      <td>0.209386</td>\n",
       "      <td>0.195539</td>\n",
       "      <td>0.466606</td>\n",
       "      <td>0.342842</td>\n",
       "      <td>0.405235</td>\n",
       "      <td>0.103734</td>\n",
       "      <td>0.276173</td>\n",
       "      <td>0.488589</td>\n",
       "      <td>0.560469</td>\n",
       "      <td>0.478734</td>\n",
       "      <td>R</td>\n",
       "      <td>180</td>\n",
       "      <td>195</td>\n",
       "      <td>0.2707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>milton_bradley_986</td>\n",
       "      <td>0.630117</td>\n",
       "      <td>0.035204</td>\n",
       "      <td>0.108187</td>\n",
       "      <td>0.335204</td>\n",
       "      <td>0.328947</td>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.371345</td>\n",
       "      <td>0.152551</td>\n",
       "      <td>0.423977</td>\n",
       "      <td>0.578571</td>\n",
       "      <td>0.627193</td>\n",
       "      <td>0.554592</td>\n",
       "      <td>R</td>\n",
       "      <td>183</td>\n",
       "      <td>215</td>\n",
       "      <td>0.2707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mike_lansing_985</td>\n",
       "      <td>0.206422</td>\n",
       "      <td>0.051296</td>\n",
       "      <td>0.040520</td>\n",
       "      <td>0.427646</td>\n",
       "      <td>0.318807</td>\n",
       "      <td>0.449784</td>\n",
       "      <td>0.308104</td>\n",
       "      <td>0.205724</td>\n",
       "      <td>0.337156</td>\n",
       "      <td>0.541037</td>\n",
       "      <td>0.573394</td>\n",
       "      <td>0.516199</td>\n",
       "      <td>R</td>\n",
       "      <td>183</td>\n",
       "      <td>175</td>\n",
       "      <td>0.2708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>kid_elberfield_984</td>\n",
       "      <td>0.097166</td>\n",
       "      <td>0.194981</td>\n",
       "      <td>0.680162</td>\n",
       "      <td>0.386100</td>\n",
       "      <td>0.859312</td>\n",
       "      <td>0.398649</td>\n",
       "      <td>0.532389</td>\n",
       "      <td>0.146236</td>\n",
       "      <td>0.408907</td>\n",
       "      <td>0.512548</td>\n",
       "      <td>0.707490</td>\n",
       "      <td>0.505792</td>\n",
       "      <td>R</td>\n",
       "      <td>170</td>\n",
       "      <td>158</td>\n",
       "      <td>0.2708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>jorge_cantu_983</td>\n",
       "      <td>0.363497</td>\n",
       "      <td>0.053672</td>\n",
       "      <td>0.131135</td>\n",
       "      <td>0.368644</td>\n",
       "      <td>0.301380</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>0.302147</td>\n",
       "      <td>0.289077</td>\n",
       "      <td>0.319785</td>\n",
       "      <td>0.590866</td>\n",
       "      <td>0.537577</td>\n",
       "      <td>0.572976</td>\n",
       "      <td>R</td>\n",
       "      <td>190</td>\n",
       "      <td>205</td>\n",
       "      <td>0.2708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bill_bradley_982</td>\n",
       "      <td>0.104839</td>\n",
       "      <td>0.107717</td>\n",
       "      <td>0.280914</td>\n",
       "      <td>0.481511</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0.459807</td>\n",
       "      <td>0.565860</td>\n",
       "      <td>0.144695</td>\n",
       "      <td>0.366935</td>\n",
       "      <td>0.504823</td>\n",
       "      <td>0.681452</td>\n",
       "      <td>0.464630</td>\n",
       "      <td>R</td>\n",
       "      <td>183</td>\n",
       "      <td>185</td>\n",
       "      <td>0.2709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>erick_aybar_981</td>\n",
       "      <td>0.358859</td>\n",
       "      <td>0.102113</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.467807</td>\n",
       "      <td>0.536787</td>\n",
       "      <td>0.504527</td>\n",
       "      <td>0.445946</td>\n",
       "      <td>0.231891</td>\n",
       "      <td>0.353604</td>\n",
       "      <td>0.551308</td>\n",
       "      <td>0.617868</td>\n",
       "      <td>0.527163</td>\n",
       "      <td>R</td>\n",
       "      <td>178</td>\n",
       "      <td>195</td>\n",
       "      <td>0.2709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>roy_white_980</td>\n",
       "      <td>0.425856</td>\n",
       "      <td>0.046537</td>\n",
       "      <td>0.859316</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.546578</td>\n",
       "      <td>0.439394</td>\n",
       "      <td>0.531369</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.518061</td>\n",
       "      <td>0.482684</td>\n",
       "      <td>0.258555</td>\n",
       "      <td>0.471861</td>\n",
       "      <td>L</td>\n",
       "      <td>178</td>\n",
       "      <td>160</td>\n",
       "      <td>0.2711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tom_herr_979</td>\n",
       "      <td>0.673137</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.802795</td>\n",
       "      <td>0.371795</td>\n",
       "      <td>0.462733</td>\n",
       "      <td>0.476282</td>\n",
       "      <td>0.479814</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.496894</td>\n",
       "      <td>0.721154</td>\n",
       "      <td>0.159161</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>L</td>\n",
       "      <td>183</td>\n",
       "      <td>175</td>\n",
       "      <td>0.2711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>christian_guzman_978</td>\n",
       "      <td>0.058673</td>\n",
       "      <td>0.011798</td>\n",
       "      <td>0.323129</td>\n",
       "      <td>0.416854</td>\n",
       "      <td>0.561224</td>\n",
       "      <td>0.447191</td>\n",
       "      <td>0.447279</td>\n",
       "      <td>0.136517</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.553371</td>\n",
       "      <td>0.582483</td>\n",
       "      <td>0.547191</td>\n",
       "      <td>R</td>\n",
       "      <td>183</td>\n",
       "      <td>180</td>\n",
       "      <td>0.2711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>edddie_matthews_977</td>\n",
       "      <td>0.522177</td>\n",
       "      <td>0.079521</td>\n",
       "      <td>0.898522</td>\n",
       "      <td>0.526144</td>\n",
       "      <td>0.452285</td>\n",
       "      <td>0.587691</td>\n",
       "      <td>0.561828</td>\n",
       "      <td>0.104031</td>\n",
       "      <td>0.581989</td>\n",
       "      <td>0.948257</td>\n",
       "      <td>0.122984</td>\n",
       "      <td>0.921024</td>\n",
       "      <td>L</td>\n",
       "      <td>185</td>\n",
       "      <td>190</td>\n",
       "      <td>0.2712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>steve_finlay_976</td>\n",
       "      <td>0.509291</td>\n",
       "      <td>0.008157</td>\n",
       "      <td>0.866554</td>\n",
       "      <td>0.245202</td>\n",
       "      <td>0.590372</td>\n",
       "      <td>0.345010</td>\n",
       "      <td>0.628378</td>\n",
       "      <td>0.156910</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.533109</td>\n",
       "      <td>0.383446</td>\n",
       "      <td>0.499520</td>\n",
       "      <td>L</td>\n",
       "      <td>188</td>\n",
       "      <td>175</td>\n",
       "      <td>0.2712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>carl_everett_975</td>\n",
       "      <td>0.466454</td>\n",
       "      <td>0.047423</td>\n",
       "      <td>0.070288</td>\n",
       "      <td>0.322165</td>\n",
       "      <td>0.269968</td>\n",
       "      <td>0.409278</td>\n",
       "      <td>0.367412</td>\n",
       "      <td>0.218041</td>\n",
       "      <td>0.320288</td>\n",
       "      <td>0.542268</td>\n",
       "      <td>0.575080</td>\n",
       "      <td>0.512887</td>\n",
       "      <td>R</td>\n",
       "      <td>183</td>\n",
       "      <td>181</td>\n",
       "      <td>0.2712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>denny_walling_974</td>\n",
       "      <td>0.659167</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.438630</td>\n",
       "      <td>0.576667</td>\n",
       "      <td>0.486434</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.167313</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.544574</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.524548</td>\n",
       "      <td>L</td>\n",
       "      <td>183</td>\n",
       "      <td>180</td>\n",
       "      <td>0.2713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>joe_morgan_973</td>\n",
       "      <td>0.805451</td>\n",
       "      <td>0.027385</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.545936</td>\n",
       "      <td>0.501880</td>\n",
       "      <td>0.573322</td>\n",
       "      <td>0.650376</td>\n",
       "      <td>0.126325</td>\n",
       "      <td>0.610902</td>\n",
       "      <td>0.648410</td>\n",
       "      <td>0.333647</td>\n",
       "      <td>0.616608</td>\n",
       "      <td>L</td>\n",
       "      <td>170</td>\n",
       "      <td>160</td>\n",
       "      <td>0.2713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>doug_mientkiewicz_972</td>\n",
       "      <td>0.803381</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.626335</td>\n",
       "      <td>0.391622</td>\n",
       "      <td>0.389680</td>\n",
       "      <td>0.369016</td>\n",
       "      <td>0.512456</td>\n",
       "      <td>0.095745</td>\n",
       "      <td>0.599644</td>\n",
       "      <td>0.515957</td>\n",
       "      <td>0.341637</td>\n",
       "      <td>0.511303</td>\n",
       "      <td>L</td>\n",
       "      <td>188</td>\n",
       "      <td>195</td>\n",
       "      <td>0.2714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sixto_lezcano_971</td>\n",
       "      <td>0.262097</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.232258</td>\n",
       "      <td>0.482955</td>\n",
       "      <td>0.374194</td>\n",
       "      <td>0.570617</td>\n",
       "      <td>0.411290</td>\n",
       "      <td>0.322240</td>\n",
       "      <td>0.458065</td>\n",
       "      <td>0.763799</td>\n",
       "      <td>0.649194</td>\n",
       "      <td>0.729708</td>\n",
       "      <td>R</td>\n",
       "      <td>178</td>\n",
       "      <td>165</td>\n",
       "      <td>0.2714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>duane_kupier_970</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.007669</td>\n",
       "      <td>0.802579</td>\n",
       "      <td>0.545245</td>\n",
       "      <td>0.405754</td>\n",
       "      <td>0.535276</td>\n",
       "      <td>0.526786</td>\n",
       "      <td>0.082822</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.299603</td>\n",
       "      <td>0.573620</td>\n",
       "      <td>L</td>\n",
       "      <td>183</td>\n",
       "      <td>175</td>\n",
       "      <td>0.2714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>norm_cash_969</td>\n",
       "      <td>0.576531</td>\n",
       "      <td>0.039666</td>\n",
       "      <td>0.856122</td>\n",
       "      <td>0.315762</td>\n",
       "      <td>0.508163</td>\n",
       "      <td>0.380480</td>\n",
       "      <td>0.568367</td>\n",
       "      <td>0.137787</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.505741</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.473382</td>\n",
       "      <td>L</td>\n",
       "      <td>183</td>\n",
       "      <td>185</td>\n",
       "      <td>0.2714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>garry_templeton_968</td>\n",
       "      <td>0.653045</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.203901</td>\n",
       "      <td>0.677083</td>\n",
       "      <td>0.327423</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.123522</td>\n",
       "      <td>0.568109</td>\n",
       "      <td>0.536052</td>\n",
       "      <td>0.349359</td>\n",
       "      <td>0.475768</td>\n",
       "      <td>L</td>\n",
       "      <td>180</td>\n",
       "      <td>175</td>\n",
       "      <td>0.2715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>rey_sanchez_967</td>\n",
       "      <td>0.395257</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.139328</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.418972</td>\n",
       "      <td>0.489216</td>\n",
       "      <td>0.411067</td>\n",
       "      <td>0.103922</td>\n",
       "      <td>0.309289</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.622530</td>\n",
       "      <td>0.719608</td>\n",
       "      <td>R</td>\n",
       "      <td>178</td>\n",
       "      <td>180</td>\n",
       "      <td>0.2715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ray_knight_966</td>\n",
       "      <td>0.362261</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>0.140127</td>\n",
       "      <td>0.331644</td>\n",
       "      <td>0.414013</td>\n",
       "      <td>0.405968</td>\n",
       "      <td>0.426752</td>\n",
       "      <td>0.083896</td>\n",
       "      <td>0.476115</td>\n",
       "      <td>0.539414</td>\n",
       "      <td>0.703025</td>\n",
       "      <td>0.524775</td>\n",
       "      <td>R</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>0.2715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>jerry_browne_965</td>\n",
       "      <td>0.375536</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.100858</td>\n",
       "      <td>0.402556</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.433706</td>\n",
       "      <td>0.326180</td>\n",
       "      <td>0.199681</td>\n",
       "      <td>0.408798</td>\n",
       "      <td>0.523962</td>\n",
       "      <td>0.615880</td>\n",
       "      <td>0.465655</td>\n",
       "      <td>R</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>0.2715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>barry_bonnell_964</td>\n",
       "      <td>0.480198</td>\n",
       "      <td>0.069322</td>\n",
       "      <td>0.129950</td>\n",
       "      <td>0.436578</td>\n",
       "      <td>0.483911</td>\n",
       "      <td>0.465339</td>\n",
       "      <td>0.408416</td>\n",
       "      <td>0.245575</td>\n",
       "      <td>0.410891</td>\n",
       "      <td>0.600295</td>\n",
       "      <td>0.674505</td>\n",
       "      <td>0.581858</td>\n",
       "      <td>R</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>0.2715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>leon_wagner_962</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.178302</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.620755</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.491509</td>\n",
       "      <td>0.492000</td>\n",
       "      <td>0.178302</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>0.546226</td>\n",
       "      <td>0.274000</td>\n",
       "      <td>0.535849</td>\n",
       "      <td>L</td>\n",
       "      <td>185</td>\n",
       "      <td>195</td>\n",
       "      <td>0.2716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>norm_siebern_961</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.131667</td>\n",
       "      <td>0.284335</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>0.055794</td>\n",
       "      <td>0.353333</td>\n",
       "      <td>0.477468</td>\n",
       "      <td>0.661667</td>\n",
       "      <td>0.463519</td>\n",
       "      <td>L</td>\n",
       "      <td>188</td>\n",
       "      <td>200</td>\n",
       "      <td>0.2716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ray_lankford_960</td>\n",
       "      <td>0.462413</td>\n",
       "      <td>0.013060</td>\n",
       "      <td>0.925699</td>\n",
       "      <td>0.285448</td>\n",
       "      <td>0.527098</td>\n",
       "      <td>0.404851</td>\n",
       "      <td>0.520105</td>\n",
       "      <td>0.133085</td>\n",
       "      <td>0.532343</td>\n",
       "      <td>0.674751</td>\n",
       "      <td>0.238636</td>\n",
       "      <td>0.608831</td>\n",
       "      <td>L</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>0.2716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>omar_vizquel_959</td>\n",
       "      <td>0.259649</td>\n",
       "      <td>0.039112</td>\n",
       "      <td>0.197368</td>\n",
       "      <td>0.418076</td>\n",
       "      <td>0.441228</td>\n",
       "      <td>0.447146</td>\n",
       "      <td>0.414035</td>\n",
       "      <td>0.225687</td>\n",
       "      <td>0.487719</td>\n",
       "      <td>0.554440</td>\n",
       "      <td>0.707018</td>\n",
       "      <td>0.492600</td>\n",
       "      <td>R</td>\n",
       "      <td>175</td>\n",
       "      <td>180</td>\n",
       "      <td>0.2718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>jeffrey_hammonds_958</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.087591</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.192822</td>\n",
       "      <td>0.249132</td>\n",
       "      <td>0.307786</td>\n",
       "      <td>0.308160</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0.365451</td>\n",
       "      <td>0.497567</td>\n",
       "      <td>0.637153</td>\n",
       "      <td>0.458637</td>\n",
       "      <td>R</td>\n",
       "      <td>183</td>\n",
       "      <td>195</td>\n",
       "      <td>0.2718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>orlando_cabrera_957</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>0.055833</td>\n",
       "      <td>0.227573</td>\n",
       "      <td>0.299167</td>\n",
       "      <td>0.305409</td>\n",
       "      <td>0.363333</td>\n",
       "      <td>0.097625</td>\n",
       "      <td>0.365000</td>\n",
       "      <td>0.542876</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.494723</td>\n",
       "      <td>R</td>\n",
       "      <td>178</td>\n",
       "      <td>195</td>\n",
       "      <td>0.2718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>adam_kennedy_956</td>\n",
       "      <td>0.412757</td>\n",
       "      <td>0.047423</td>\n",
       "      <td>0.722141</td>\n",
       "      <td>0.252062</td>\n",
       "      <td>0.550587</td>\n",
       "      <td>0.360309</td>\n",
       "      <td>0.563050</td>\n",
       "      <td>0.160309</td>\n",
       "      <td>0.586510</td>\n",
       "      <td>0.469588</td>\n",
       "      <td>0.372434</td>\n",
       "      <td>0.458247</td>\n",
       "      <td>L</td>\n",
       "      <td>180</td>\n",
       "      <td>195</td>\n",
       "      <td>0.2719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>dwight_evans_955</td>\n",
       "      <td>0.429365</td>\n",
       "      <td>0.139755</td>\n",
       "      <td>0.080159</td>\n",
       "      <td>0.328508</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.431514</td>\n",
       "      <td>0.384127</td>\n",
       "      <td>0.168151</td>\n",
       "      <td>0.363492</td>\n",
       "      <td>0.512249</td>\n",
       "      <td>0.606349</td>\n",
       "      <td>0.477171</td>\n",
       "      <td>R</td>\n",
       "      <td>188</td>\n",
       "      <td>180</td>\n",
       "      <td>0.2719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ken_camniniti_954</td>\n",
       "      <td>0.724359</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.895032</td>\n",
       "      <td>0.431057</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.447809</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.143686</td>\n",
       "      <td>0.625801</td>\n",
       "      <td>0.521907</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>0.471649</td>\n",
       "      <td>L</td>\n",
       "      <td>183</td>\n",
       "      <td>200</td>\n",
       "      <td>0.2719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>marquis_grissom_953</td>\n",
       "      <td>0.291379</td>\n",
       "      <td>0.045768</td>\n",
       "      <td>0.261207</td>\n",
       "      <td>0.391240</td>\n",
       "      <td>0.528448</td>\n",
       "      <td>0.477854</td>\n",
       "      <td>0.442241</td>\n",
       "      <td>0.242618</td>\n",
       "      <td>0.368103</td>\n",
       "      <td>0.551673</td>\n",
       "      <td>0.623276</td>\n",
       "      <td>0.549213</td>\n",
       "      <td>R</td>\n",
       "      <td>180</td>\n",
       "      <td>190</td>\n",
       "      <td>0.2720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ivan_calderon_952</td>\n",
       "      <td>0.359259</td>\n",
       "      <td>0.046036</td>\n",
       "      <td>0.173148</td>\n",
       "      <td>0.223785</td>\n",
       "      <td>0.403704</td>\n",
       "      <td>0.337596</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.075448</td>\n",
       "      <td>0.401852</td>\n",
       "      <td>0.489130</td>\n",
       "      <td>0.702778</td>\n",
       "      <td>0.459719</td>\n",
       "      <td>R</td>\n",
       "      <td>185</td>\n",
       "      <td>220</td>\n",
       "      <td>0.2720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>wally_westlake_951</td>\n",
       "      <td>0.292328</td>\n",
       "      <td>0.081132</td>\n",
       "      <td>0.072751</td>\n",
       "      <td>0.387736</td>\n",
       "      <td>0.498677</td>\n",
       "      <td>0.497170</td>\n",
       "      <td>0.421958</td>\n",
       "      <td>0.174528</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.828302</td>\n",
       "      <td>0.921958</td>\n",
       "      <td>0.781132</td>\n",
       "      <td>R</td>\n",
       "      <td>183</td>\n",
       "      <td>186</td>\n",
       "      <td>0.2721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>bobby_higginson_950</td>\n",
       "      <td>0.645186</td>\n",
       "      <td>0.032242</td>\n",
       "      <td>0.906832</td>\n",
       "      <td>0.410218</td>\n",
       "      <td>0.670807</td>\n",
       "      <td>0.473710</td>\n",
       "      <td>0.622671</td>\n",
       "      <td>0.230655</td>\n",
       "      <td>0.680901</td>\n",
       "      <td>0.543155</td>\n",
       "      <td>0.430124</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>L</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>0.2721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>marcel_ozuna-949</td>\n",
       "      <td>0.317308</td>\n",
       "      <td>0.075843</td>\n",
       "      <td>0.180556</td>\n",
       "      <td>0.452949</td>\n",
       "      <td>0.429487</td>\n",
       "      <td>0.525281</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>0.262640</td>\n",
       "      <td>0.344017</td>\n",
       "      <td>0.591994</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>R</td>\n",
       "      <td>185</td>\n",
       "      <td>225</td>\n",
       "      <td>0.2723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Player      T1_1      T1_2      T2_1      T2_2      T3_1  \\\n",
       "0       mike_marshall_999  0.500723  0.019169  0.096098  0.576677  0.379335   \n",
       "1     alfonso_soriano_998  0.526171  0.002045  0.055096  0.237219  0.292011   \n",
       "2           jody_reed_997  0.464928  0.004630  0.079137  0.461640  0.373201   \n",
       "3          kevin_bass_996  0.477839  0.020161  0.931440  0.307460  0.623269   \n",
       "4       jason_barlett_995  0.424769  0.003546  0.125000  0.348404  0.445602   \n",
       "5       bobby_thomson_994  0.479962  0.127743  0.229008  0.507837  0.478053   \n",
       "6        rube_oldring_993  0.702236  0.203125  0.239837  0.382812  0.434959   \n",
       "7         bill_spiers_992  0.421053  0.006925  0.862664  0.296399  0.702303   \n",
       "8      glenallen_hill_991  0.236891  0.006631  0.324906  0.289125  0.524345   \n",
       "9     terry_steinbach_990  0.298817  0.007229  0.139053  0.219880  0.323225   \n",
       "10          cory_hart_989  0.467470  0.035965  0.109639  0.359649  0.357831   \n",
       "11     tino_martiniez_988  0.640625  0.052500  0.835069  0.297000  0.605035   \n",
       "12       omar_infante_987  0.614621  0.113071  0.209386  0.195539  0.466606   \n",
       "13     milton_bradley_986  0.630117  0.035204  0.108187  0.335204  0.328947   \n",
       "14       mike_lansing_985  0.206422  0.051296  0.040520  0.427646  0.318807   \n",
       "15     kid_elberfield_984  0.097166  0.194981  0.680162  0.386100  0.859312   \n",
       "16        jorge_cantu_983  0.363497  0.053672  0.131135  0.368644  0.301380   \n",
       "17       bill_bradley_982  0.104839  0.107717  0.280914  0.481511  0.564516   \n",
       "18        erick_aybar_981  0.358859  0.102113  0.337838  0.467807  0.536787   \n",
       "19          roy_white_980  0.425856  0.046537  0.859316  0.404762  0.546578   \n",
       "20           tom_herr_979  0.673137  0.008333  0.802795  0.371795  0.462733   \n",
       "21   christian_guzman_978  0.058673  0.011798  0.323129  0.416854  0.561224   \n",
       "22    edddie_matthews_977  0.522177  0.079521  0.898522  0.526144  0.452285   \n",
       "23       steve_finlay_976  0.509291  0.008157  0.866554  0.245202  0.590372   \n",
       "24       carl_everett_975  0.466454  0.047423  0.070288  0.322165  0.269968   \n",
       "25      denny_walling_974  0.659167  0.015504  0.810000  0.438630  0.576667   \n",
       "26         joe_morgan_973  0.805451  0.027385  0.789474  0.545936  0.501880   \n",
       "27  doug_mientkiewicz_972  0.803381  0.007979  0.626335  0.391622  0.389680   \n",
       "28      sixto_lezcano_971  0.262097  0.012987  0.232258  0.482955  0.374194   \n",
       "29       duane_kupier_970  0.682540  0.007669  0.802579  0.545245  0.405754   \n",
       "30          norm_cash_969  0.576531  0.039666  0.856122  0.315762  0.508163   \n",
       "31    garry_templeton_968  0.653045  0.007092  0.935897  0.203901  0.677083   \n",
       "32        rey_sanchez_967  0.395257  0.004902  0.139328  0.338235  0.418972   \n",
       "33         ray_knight_966  0.362261  0.003941  0.140127  0.331644  0.414013   \n",
       "34       jerry_browne_965  0.375536  0.004792  0.100858  0.402556  0.300429   \n",
       "35      barry_bonnell_964  0.480198  0.069322  0.129950  0.436578  0.483911   \n",
       "36        leon_wagner_962  0.868000  0.178302  0.512000  0.620755  0.218000   \n",
       "37       norm_siebern_961  0.270000  0.004292  0.131667  0.284335  0.455000   \n",
       "38       ray_lankford_960  0.462413  0.013060  0.925699  0.285448  0.527098   \n",
       "39       omar_vizquel_959  0.259649  0.039112  0.197368  0.418076  0.441228   \n",
       "40   jeffrey_hammonds_958  0.583333  0.087591  0.031250  0.192822  0.249132   \n",
       "41    orlando_cabrera_957  0.610000  0.007256  0.055833  0.227573  0.299167   \n",
       "42       adam_kennedy_956  0.412757  0.047423  0.722141  0.252062  0.550587   \n",
       "43       dwight_evans_955  0.429365  0.139755  0.080159  0.328508  0.355556   \n",
       "44      ken_camniniti_954  0.724359  0.005799  0.895032  0.431057  0.641026   \n",
       "45    marquis_grissom_953  0.291379  0.045768  0.261207  0.391240  0.528448   \n",
       "46      ivan_calderon_952  0.359259  0.046036  0.173148  0.223785  0.403704   \n",
       "47     wally_westlake_951  0.292328  0.081132  0.072751  0.387736  0.498677   \n",
       "48    bobby_higginson_950  0.645186  0.032242  0.906832  0.410218  0.670807   \n",
       "49       marcel_ozuna-949  0.317308  0.075843  0.180556  0.452949  0.429487   \n",
       "\n",
       "        T3_2      H1_1      H1_2      H2_1      H2_2      H3_1      H3_2 hand  \\\n",
       "0   0.605431  0.413295  0.137380  0.497110  0.715655  0.734827  0.645367    R   \n",
       "1   0.388037  0.365014  0.171779  0.436639  0.527607  0.630165  0.514315    R   \n",
       "2   0.490079  0.438849  0.112434  0.566547  0.713624  0.872302  0.660053    R   \n",
       "3   0.403226  0.584488  0.099798  0.493075  0.564516  0.198061  0.521169    L   \n",
       "4   0.480496  0.493056  0.097518  0.400463  0.738475  0.788194  0.731383    R   \n",
       "5   0.542320  0.485687  0.167712  0.458969  0.721787  0.743321  0.709248    R   \n",
       "6   0.414062  0.526423  0.213778  0.470528  0.566051  0.706301  0.529119    R   \n",
       "7   0.351801  0.661184  0.047784  0.541118  0.468837  0.318257  0.409280    L   \n",
       "8   0.322944  0.432584  0.094164  0.365169  0.415119  0.571161  0.391910    R   \n",
       "9   0.343373  0.378698  0.056024  0.434911  0.490964  0.695266  0.444578    R   \n",
       "10  0.419737  0.392771  0.160965  0.362651  0.535088  0.618675  0.501316    R   \n",
       "11  0.391000  0.625868  0.178000  0.642361  0.542000  0.392361  0.517500    L   \n",
       "12  0.342842  0.405235  0.103734  0.276173  0.488589  0.560469  0.478734    R   \n",
       "13  0.442857  0.371345  0.152551  0.423977  0.578571  0.627193  0.554592    R   \n",
       "14  0.449784  0.308104  0.205724  0.337156  0.541037  0.573394  0.516199    R   \n",
       "15  0.398649  0.532389  0.146236  0.408907  0.512548  0.707490  0.505792    R   \n",
       "16  0.474576  0.302147  0.289077  0.319785  0.590866  0.537577  0.572976    R   \n",
       "17  0.459807  0.565860  0.144695  0.366935  0.504823  0.681452  0.464630    R   \n",
       "18  0.504527  0.445946  0.231891  0.353604  0.551308  0.617868  0.527163    R   \n",
       "19  0.439394  0.531369  0.121212  0.518061  0.482684  0.258555  0.471861    L   \n",
       "20  0.476282  0.479814  0.115385  0.496894  0.721154  0.159161  0.679487    L   \n",
       "21  0.447191  0.447279  0.136517  0.250000  0.553371  0.582483  0.547191    R   \n",
       "22  0.587691  0.561828  0.104031  0.581989  0.948257  0.122984  0.921024    L   \n",
       "23  0.345010  0.628378  0.156910  0.662162  0.533109  0.383446  0.499520    L   \n",
       "24  0.409278  0.367412  0.218041  0.320288  0.542268  0.575080  0.512887    R   \n",
       "25  0.486434  0.600000  0.167313  0.625000  0.544574  0.408333  0.524548    L   \n",
       "26  0.573322  0.650376  0.126325  0.610902  0.648410  0.333647  0.616608    L   \n",
       "27  0.369016  0.512456  0.095745  0.599644  0.515957  0.341637  0.511303    L   \n",
       "28  0.570617  0.411290  0.322240  0.458065  0.763799  0.649194  0.729708    R   \n",
       "29  0.535276  0.526786  0.082822  0.603175  0.582822  0.299603  0.573620    L   \n",
       "30  0.380480  0.568367  0.137787  0.704082  0.505741  0.326531  0.473382    L   \n",
       "31  0.327423  0.615385  0.123522  0.568109  0.536052  0.349359  0.475768    L   \n",
       "32  0.489216  0.411067  0.103922  0.309289  0.756863  0.622530  0.719608    R   \n",
       "33  0.405968  0.426752  0.083896  0.476115  0.539414  0.703025  0.524775    R   \n",
       "34  0.433706  0.326180  0.199681  0.408798  0.523962  0.615880  0.465655    R   \n",
       "35  0.465339  0.408416  0.245575  0.410891  0.600295  0.674505  0.581858    R   \n",
       "36  0.491509  0.492000  0.178302  0.704000  0.546226  0.274000  0.535849    L   \n",
       "37  0.313305  0.435000  0.055794  0.353333  0.477468  0.661667  0.463519    L   \n",
       "38  0.404851  0.520105  0.133085  0.532343  0.674751  0.238636  0.608831    L   \n",
       "39  0.447146  0.414035  0.225687  0.487719  0.554440  0.707018  0.492600    R   \n",
       "40  0.307786  0.308160  0.113139  0.365451  0.497567  0.637153  0.458637    R   \n",
       "41  0.305409  0.363333  0.097625  0.365000  0.542876  0.606667  0.494723    R   \n",
       "42  0.360309  0.563050  0.160309  0.586510  0.469588  0.372434  0.458247    L   \n",
       "43  0.431514  0.384127  0.168151  0.363492  0.512249  0.606349  0.477171    R   \n",
       "44  0.447809  0.653846  0.143686  0.625801  0.521907  0.412660  0.471649    L   \n",
       "45  0.477854  0.442241  0.242618  0.368103  0.551673  0.623276  0.549213    R   \n",
       "46  0.337596  0.400000  0.075448  0.401852  0.489130  0.702778  0.459719    R   \n",
       "47  0.497170  0.421958  0.174528  0.464286  0.828302  0.921958  0.781132    R   \n",
       "48  0.473710  0.622671  0.230655  0.680901  0.543155  0.430124  0.500000    L   \n",
       "49  0.525281  0.442308  0.262640  0.344017  0.591994  0.602564  0.562500    R   \n",
       "\n",
       "    height  weight      BA  \n",
       "0      196     215  0.2702  \n",
       "1      185     195  0.2703  \n",
       "2      175     170  0.2703  \n",
       "3      183     183  0.2703  \n",
       "4      183     190  0.2703  \n",
       "5      188     180  0.2704  \n",
       "6      178     186  0.2704  \n",
       "7      188     190  0.2705  \n",
       "8      190     210  0.2705  \n",
       "9      185     195  0.2706  \n",
       "10     198     240  0.2706  \n",
       "11     188     205  0.2707  \n",
       "12     180     195  0.2707  \n",
       "13     183     215  0.2707  \n",
       "14     183     175  0.2708  \n",
       "15     170     158  0.2708  \n",
       "16     190     205  0.2708  \n",
       "17     183     185  0.2709  \n",
       "18     178     195  0.2709  \n",
       "19     178     160  0.2711  \n",
       "20     183     175  0.2711  \n",
       "21     183     180  0.2711  \n",
       "22     185     190  0.2712  \n",
       "23     188     175  0.2712  \n",
       "24     183     181  0.2712  \n",
       "25     183     180  0.2713  \n",
       "26     170     160  0.2713  \n",
       "27     188     195  0.2714  \n",
       "28     178     165  0.2714  \n",
       "29     183     175  0.2714  \n",
       "30     183     185  0.2714  \n",
       "31     180     175  0.2715  \n",
       "32     178     180  0.2715  \n",
       "33     185     185  0.2715  \n",
       "34     185     185  0.2715  \n",
       "35     190     190  0.2715  \n",
       "36     185     195  0.2716  \n",
       "37     188     200  0.2716  \n",
       "38     180     180  0.2716  \n",
       "39     175     180  0.2718  \n",
       "40     183     195  0.2718  \n",
       "41     178     195  0.2718  \n",
       "42     180     195  0.2719  \n",
       "43     188     180  0.2719  \n",
       "44     183     200  0.2719  \n",
       "45     180     190  0.2720  \n",
       "46     185     220  0.2720  \n",
       "47     183     186  0.2721  \n",
       "48     180     180  0.2721  \n",
       "49     185     225  0.2723  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    " \n",
    "def getAngle(a, b, c):\n",
    "    ang = math.degrees(math.atan2(c[1]-b[1], c[0]-b[0]) - math.atan2(a[1]-b[1], a[0]-b[0]))\n",
    "    return ang + 360 if ang < 0 else ang\n",
    "\n",
    "df['Angle1'] = df.apply(lambda x: getAngle((x['T1_1'],x['T1_2']),(x['T2_1'],x['T2_2']),(x['T3_1'],x['T3_2'])),axis=1)\n",
    "df['Angle2'] = df.apply(lambda x: getAngle((x['H1_1'],x['H1_2']),(x['H2_1'],x['H2_2']),(x['H3_1'],x['H3_2'])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>T1_1</th>\n",
       "      <th>T1_2</th>\n",
       "      <th>T2_1</th>\n",
       "      <th>T2_2</th>\n",
       "      <th>T3_1</th>\n",
       "      <th>T3_2</th>\n",
       "      <th>H1_1</th>\n",
       "      <th>H1_2</th>\n",
       "      <th>H2_1</th>\n",
       "      <th>H2_2</th>\n",
       "      <th>H3_1</th>\n",
       "      <th>H3_2</th>\n",
       "      <th>hand</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BA</th>\n",
       "      <th>Angle1</th>\n",
       "      <th>Angle2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mike_marshall_999</td>\n",
       "      <td>0.500723</td>\n",
       "      <td>0.019169</td>\n",
       "      <td>0.096098</td>\n",
       "      <td>0.576677</td>\n",
       "      <td>0.379335</td>\n",
       "      <td>0.605431</td>\n",
       "      <td>0.413295</td>\n",
       "      <td>0.137380</td>\n",
       "      <td>0.497110</td>\n",
       "      <td>0.715655</td>\n",
       "      <td>0.734827</td>\n",
       "      <td>0.645367</td>\n",
       "      <td>R</td>\n",
       "      <td>196</td>\n",
       "      <td>215</td>\n",
       "      <td>0.2702</td>\n",
       "      <td>59.825581</td>\n",
       "      <td>81.775144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfonso_soriano_998</td>\n",
       "      <td>0.526171</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.055096</td>\n",
       "      <td>0.237219</td>\n",
       "      <td>0.292011</td>\n",
       "      <td>0.388037</td>\n",
       "      <td>0.365014</td>\n",
       "      <td>0.171779</td>\n",
       "      <td>0.436639</td>\n",
       "      <td>0.527607</td>\n",
       "      <td>0.630165</td>\n",
       "      <td>0.514315</td>\n",
       "      <td>R</td>\n",
       "      <td>185</td>\n",
       "      <td>195</td>\n",
       "      <td>0.2703</td>\n",
       "      <td>59.010142</td>\n",
       "      <td>97.451951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jody_reed_997</td>\n",
       "      <td>0.464928</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.079137</td>\n",
       "      <td>0.461640</td>\n",
       "      <td>0.373201</td>\n",
       "      <td>0.490079</td>\n",
       "      <td>0.438849</td>\n",
       "      <td>0.112434</td>\n",
       "      <td>0.566547</td>\n",
       "      <td>0.713624</td>\n",
       "      <td>0.872302</td>\n",
       "      <td>0.660053</td>\n",
       "      <td>R</td>\n",
       "      <td>175</td>\n",
       "      <td>170</td>\n",
       "      <td>0.2703</td>\n",
       "      <td>55.354085</td>\n",
       "      <td>92.054036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kevin_bass_996</td>\n",
       "      <td>0.477839</td>\n",
       "      <td>0.020161</td>\n",
       "      <td>0.931440</td>\n",
       "      <td>0.307460</td>\n",
       "      <td>0.623269</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.584488</td>\n",
       "      <td>0.099798</td>\n",
       "      <td>0.493075</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0.198061</td>\n",
       "      <td>0.521169</td>\n",
       "      <td>L</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>0.2703</td>\n",
       "      <td>310.387953</td>\n",
       "      <td>267.230408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jason_barlett_995</td>\n",
       "      <td>0.424769</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.348404</td>\n",
       "      <td>0.445602</td>\n",
       "      <td>0.480496</td>\n",
       "      <td>0.493056</td>\n",
       "      <td>0.097518</td>\n",
       "      <td>0.400463</td>\n",
       "      <td>0.738475</td>\n",
       "      <td>0.788194</td>\n",
       "      <td>0.731383</td>\n",
       "      <td>R</td>\n",
       "      <td>183</td>\n",
       "      <td>190</td>\n",
       "      <td>0.2703</td>\n",
       "      <td>71.393355</td>\n",
       "      <td>80.732005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bobby_thomson_994</td>\n",
       "      <td>0.479962</td>\n",
       "      <td>0.127743</td>\n",
       "      <td>0.229008</td>\n",
       "      <td>0.507837</td>\n",
       "      <td>0.478053</td>\n",
       "      <td>0.542320</td>\n",
       "      <td>0.485687</td>\n",
       "      <td>0.167712</td>\n",
       "      <td>0.458969</td>\n",
       "      <td>0.721787</td>\n",
       "      <td>0.743321</td>\n",
       "      <td>0.709248</td>\n",
       "      <td>R</td>\n",
       "      <td>188</td>\n",
       "      <td>180</td>\n",
       "      <td>0.2704</td>\n",
       "      <td>64.448638</td>\n",
       "      <td>84.714362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rube_oldring_993</td>\n",
       "      <td>0.702236</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.239837</td>\n",
       "      <td>0.382812</td>\n",
       "      <td>0.434959</td>\n",
       "      <td>0.414062</td>\n",
       "      <td>0.526423</td>\n",
       "      <td>0.213778</td>\n",
       "      <td>0.470528</td>\n",
       "      <td>0.566051</td>\n",
       "      <td>0.706301</td>\n",
       "      <td>0.529119</td>\n",
       "      <td>R</td>\n",
       "      <td>178</td>\n",
       "      <td>186</td>\n",
       "      <td>0.2704</td>\n",
       "      <td>30.334995</td>\n",
       "      <td>72.081471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bill_spiers_992</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.006925</td>\n",
       "      <td>0.862664</td>\n",
       "      <td>0.296399</td>\n",
       "      <td>0.702303</td>\n",
       "      <td>0.351801</td>\n",
       "      <td>0.661184</td>\n",
       "      <td>0.047784</td>\n",
       "      <td>0.541118</td>\n",
       "      <td>0.468837</td>\n",
       "      <td>0.318257</td>\n",
       "      <td>0.409280</td>\n",
       "      <td>L</td>\n",
       "      <td>188</td>\n",
       "      <td>190</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>307.696180</td>\n",
       "      <td>269.046147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>glenallen_hill_991</td>\n",
       "      <td>0.236891</td>\n",
       "      <td>0.006631</td>\n",
       "      <td>0.324906</td>\n",
       "      <td>0.289125</td>\n",
       "      <td>0.524345</td>\n",
       "      <td>0.322944</td>\n",
       "      <td>0.432584</td>\n",
       "      <td>0.094164</td>\n",
       "      <td>0.365169</td>\n",
       "      <td>0.415119</td>\n",
       "      <td>0.571161</td>\n",
       "      <td>0.391910</td>\n",
       "      <td>R</td>\n",
       "      <td>190</td>\n",
       "      <td>210</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>116.929296</td>\n",
       "      <td>71.709378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>terry_steinbach_990</td>\n",
       "      <td>0.298817</td>\n",
       "      <td>0.007229</td>\n",
       "      <td>0.139053</td>\n",
       "      <td>0.219880</td>\n",
       "      <td>0.323225</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.378698</td>\n",
       "      <td>0.056024</td>\n",
       "      <td>0.434911</td>\n",
       "      <td>0.490964</td>\n",
       "      <td>0.695266</td>\n",
       "      <td>0.444578</td>\n",
       "      <td>R</td>\n",
       "      <td>185</td>\n",
       "      <td>195</td>\n",
       "      <td>0.2706</td>\n",
       "      <td>86.925652</td>\n",
       "      <td>87.262191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cory_hart_989</td>\n",
       "      <td>0.467470</td>\n",
       "      <td>0.035965</td>\n",
       "      <td>0.109639</td>\n",
       "      <td>0.359649</td>\n",
       "      <td>0.357831</td>\n",
       "      <td>0.419737</td>\n",
       "      <td>0.392771</td>\n",
       "      <td>0.160965</td>\n",
       "      <td>0.362651</td>\n",
       "      <td>0.535088</td>\n",
       "      <td>0.618675</td>\n",
       "      <td>0.501316</td>\n",
       "      <td>R</td>\n",
       "      <td>198</td>\n",
       "      <td>240</td>\n",
       "      <td>0.2706</td>\n",
       "      <td>55.741223</td>\n",
       "      <td>77.882668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tino_martiniez_988</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.835069</td>\n",
       "      <td>0.297000</td>\n",
       "      <td>0.605035</td>\n",
       "      <td>0.391000</td>\n",
       "      <td>0.625868</td>\n",
       "      <td>0.178000</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.542000</td>\n",
       "      <td>0.392361</td>\n",
       "      <td>0.517500</td>\n",
       "      <td>L</td>\n",
       "      <td>188</td>\n",
       "      <td>205</td>\n",
       "      <td>0.2707</td>\n",
       "      <td>286.267591</td>\n",
       "      <td>278.191436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>omar_infante_987</td>\n",
       "      <td>0.614621</td>\n",
       "      <td>0.113071</td>\n",
       "      <td>0.209386</td>\n",
       "      <td>0.195539</td>\n",
       "      <td>0.466606</td>\n",
       "      <td>0.342842</td>\n",
       "      <td>0.405235</td>\n",
       "      <td>0.103734</td>\n",
       "      <td>0.276173</td>\n",
       "      <td>0.488589</td>\n",
       "      <td>0.560469</td>\n",
       "      <td>0.478734</td>\n",
       "      <td>R</td>\n",
       "      <td>180</td>\n",
       "      <td>195</td>\n",
       "      <td>0.2707</td>\n",
       "      <td>41.301599</td>\n",
       "      <td>69.475666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>milton_bradley_986</td>\n",
       "      <td>0.630117</td>\n",
       "      <td>0.035204</td>\n",
       "      <td>0.108187</td>\n",
       "      <td>0.335204</td>\n",
       "      <td>0.328947</td>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.371345</td>\n",
       "      <td>0.152551</td>\n",
       "      <td>0.423977</td>\n",
       "      <td>0.578571</td>\n",
       "      <td>0.627193</td>\n",
       "      <td>0.554592</td>\n",
       "      <td>R</td>\n",
       "      <td>183</td>\n",
       "      <td>215</td>\n",
       "      <td>0.2707</td>\n",
       "      <td>55.885895</td>\n",
       "      <td>90.313188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mike_lansing_985</td>\n",
       "      <td>0.206422</td>\n",
       "      <td>0.051296</td>\n",
       "      <td>0.040520</td>\n",
       "      <td>0.427646</td>\n",
       "      <td>0.318807</td>\n",
       "      <td>0.449784</td>\n",
       "      <td>0.308104</td>\n",
       "      <td>0.205724</td>\n",
       "      <td>0.337156</td>\n",
       "      <td>0.541037</td>\n",
       "      <td>0.573394</td>\n",
       "      <td>0.516199</td>\n",
       "      <td>R</td>\n",
       "      <td>183</td>\n",
       "      <td>175</td>\n",
       "      <td>0.2708</td>\n",
       "      <td>70.759589</td>\n",
       "      <td>88.949811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>kid_elberfield_984</td>\n",
       "      <td>0.097166</td>\n",
       "      <td>0.194981</td>\n",
       "      <td>0.680162</td>\n",
       "      <td>0.386100</td>\n",
       "      <td>0.859312</td>\n",
       "      <td>0.398649</td>\n",
       "      <td>0.532389</td>\n",
       "      <td>0.146236</td>\n",
       "      <td>0.408907</td>\n",
       "      <td>0.512548</td>\n",
       "      <td>0.707490</td>\n",
       "      <td>0.505792</td>\n",
       "      <td>R</td>\n",
       "      <td>170</td>\n",
       "      <td>158</td>\n",
       "      <td>0.2708</td>\n",
       "      <td>165.856589</td>\n",
       "      <td>70.075085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>jorge_cantu_983</td>\n",
       "      <td>0.363497</td>\n",
       "      <td>0.053672</td>\n",
       "      <td>0.131135</td>\n",
       "      <td>0.368644</td>\n",
       "      <td>0.301380</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>0.302147</td>\n",
       "      <td>0.289077</td>\n",
       "      <td>0.319785</td>\n",
       "      <td>0.590866</td>\n",
       "      <td>0.537577</td>\n",
       "      <td>0.572976</td>\n",
       "      <td>R</td>\n",
       "      <td>190</td>\n",
       "      <td>205</td>\n",
       "      <td>0.2708</td>\n",
       "      <td>85.474184</td>\n",
       "      <td>88.648955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bill_bradley_982</td>\n",
       "      <td>0.104839</td>\n",
       "      <td>0.107717</td>\n",
       "      <td>0.280914</td>\n",
       "      <td>0.481511</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0.459807</td>\n",
       "      <td>0.565860</td>\n",
       "      <td>0.144695</td>\n",
       "      <td>0.366935</td>\n",
       "      <td>0.504823</td>\n",
       "      <td>0.681452</td>\n",
       "      <td>0.464630</td>\n",
       "      <td>R</td>\n",
       "      <td>183</td>\n",
       "      <td>185</td>\n",
       "      <td>0.2709</td>\n",
       "      <td>110.846394</td>\n",
       "      <td>53.802409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>erick_aybar_981</td>\n",
       "      <td>0.358859</td>\n",
       "      <td>0.102113</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.467807</td>\n",
       "      <td>0.536787</td>\n",
       "      <td>0.504527</td>\n",
       "      <td>0.445946</td>\n",
       "      <td>0.231891</td>\n",
       "      <td>0.353604</td>\n",
       "      <td>0.551308</td>\n",
       "      <td>0.617868</td>\n",
       "      <td>0.527163</td>\n",
       "      <td>R</td>\n",
       "      <td>178</td>\n",
       "      <td>195</td>\n",
       "      <td>0.2709</td>\n",
       "      <td>97.167506</td>\n",
       "      <td>68.655212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>roy_white_980</td>\n",
       "      <td>0.425856</td>\n",
       "      <td>0.046537</td>\n",
       "      <td>0.859316</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.546578</td>\n",
       "      <td>0.439394</td>\n",
       "      <td>0.531369</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.518061</td>\n",
       "      <td>0.482684</td>\n",
       "      <td>0.258555</td>\n",
       "      <td>0.471861</td>\n",
       "      <td>L</td>\n",
       "      <td>178</td>\n",
       "      <td>160</td>\n",
       "      <td>0.2711</td>\n",
       "      <td>314.109523</td>\n",
       "      <td>270.279747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tom_herr_979</td>\n",
       "      <td>0.673137</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.802795</td>\n",
       "      <td>0.371795</td>\n",
       "      <td>0.462733</td>\n",
       "      <td>0.476282</td>\n",
       "      <td>0.479814</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.496894</td>\n",
       "      <td>0.721154</td>\n",
       "      <td>0.159161</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>L</td>\n",
       "      <td>183</td>\n",
       "      <td>175</td>\n",
       "      <td>0.2711</td>\n",
       "      <td>272.552841</td>\n",
       "      <td>278.648249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>christian_guzman_978</td>\n",
       "      <td>0.058673</td>\n",
       "      <td>0.011798</td>\n",
       "      <td>0.323129</td>\n",
       "      <td>0.416854</td>\n",
       "      <td>0.561224</td>\n",
       "      <td>0.447191</td>\n",
       "      <td>0.447279</td>\n",
       "      <td>0.136517</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.553371</td>\n",
       "      <td>0.582483</td>\n",
       "      <td>0.547191</td>\n",
       "      <td>R</td>\n",
       "      <td>183</td>\n",
       "      <td>180</td>\n",
       "      <td>0.2711</td>\n",
       "      <td>130.401264</td>\n",
       "      <td>63.608969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>edddie_matthews_977</td>\n",
       "      <td>0.522177</td>\n",
       "      <td>0.079521</td>\n",
       "      <td>0.898522</td>\n",
       "      <td>0.526144</td>\n",
       "      <td>0.452285</td>\n",
       "      <td>0.587691</td>\n",
       "      <td>0.561828</td>\n",
       "      <td>0.104031</td>\n",
       "      <td>0.581989</td>\n",
       "      <td>0.948257</td>\n",
       "      <td>0.122984</td>\n",
       "      <td>0.921024</td>\n",
       "      <td>L</td>\n",
       "      <td>185</td>\n",
       "      <td>190</td>\n",
       "      <td>0.2712</td>\n",
       "      <td>302.266080</td>\n",
       "      <td>274.763431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>steve_finlay_976</td>\n",
       "      <td>0.509291</td>\n",
       "      <td>0.008157</td>\n",
       "      <td>0.866554</td>\n",
       "      <td>0.245202</td>\n",
       "      <td>0.590372</td>\n",
       "      <td>0.345010</td>\n",
       "      <td>0.628378</td>\n",
       "      <td>0.156910</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.533109</td>\n",
       "      <td>0.383446</td>\n",
       "      <td>0.499520</td>\n",
       "      <td>L</td>\n",
       "      <td>188</td>\n",
       "      <td>175</td>\n",
       "      <td>0.2712</td>\n",
       "      <td>306.566525</td>\n",
       "      <td>282.003365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>carl_everett_975</td>\n",
       "      <td>0.466454</td>\n",
       "      <td>0.047423</td>\n",
       "      <td>0.070288</td>\n",
       "      <td>0.322165</td>\n",
       "      <td>0.269968</td>\n",
       "      <td>0.409278</td>\n",
       "      <td>0.367412</td>\n",
       "      <td>0.218041</td>\n",
       "      <td>0.320288</td>\n",
       "      <td>0.542268</td>\n",
       "      <td>0.575080</td>\n",
       "      <td>0.512887</td>\n",
       "      <td>R</td>\n",
       "      <td>183</td>\n",
       "      <td>181</td>\n",
       "      <td>0.2712</td>\n",
       "      <td>58.311257</td>\n",
       "      <td>75.152455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>denny_walling_974</td>\n",
       "      <td>0.659167</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.438630</td>\n",
       "      <td>0.576667</td>\n",
       "      <td>0.486434</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.167313</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.544574</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.524548</td>\n",
       "      <td>L</td>\n",
       "      <td>183</td>\n",
       "      <td>180</td>\n",
       "      <td>0.2713</td>\n",
       "      <td>278.041549</td>\n",
       "      <td>279.071988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>joe_morgan_973</td>\n",
       "      <td>0.805451</td>\n",
       "      <td>0.027385</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.545936</td>\n",
       "      <td>0.501880</td>\n",
       "      <td>0.573322</td>\n",
       "      <td>0.650376</td>\n",
       "      <td>0.126325</td>\n",
       "      <td>0.610902</td>\n",
       "      <td>0.648410</td>\n",
       "      <td>0.333647</td>\n",
       "      <td>0.616608</td>\n",
       "      <td>L</td>\n",
       "      <td>170</td>\n",
       "      <td>160</td>\n",
       "      <td>0.2713</td>\n",
       "      <td>262.795665</td>\n",
       "      <td>272.219591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>doug_mientkiewicz_972</td>\n",
       "      <td>0.803381</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.626335</td>\n",
       "      <td>0.391622</td>\n",
       "      <td>0.389680</td>\n",
       "      <td>0.369016</td>\n",
       "      <td>0.512456</td>\n",
       "      <td>0.095745</td>\n",
       "      <td>0.599644</td>\n",
       "      <td>0.515957</td>\n",
       "      <td>0.341637</td>\n",
       "      <td>0.511303</td>\n",
       "      <td>L</td>\n",
       "      <td>188</td>\n",
       "      <td>195</td>\n",
       "      <td>0.2714</td>\n",
       "      <td>250.683832</td>\n",
       "      <td>282.755143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sixto_lezcano_971</td>\n",
       "      <td>0.262097</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.232258</td>\n",
       "      <td>0.482955</td>\n",
       "      <td>0.374194</td>\n",
       "      <td>0.570617</td>\n",
       "      <td>0.411290</td>\n",
       "      <td>0.322240</td>\n",
       "      <td>0.458065</td>\n",
       "      <td>0.763799</td>\n",
       "      <td>0.649194</td>\n",
       "      <td>0.729708</td>\n",
       "      <td>R</td>\n",
       "      <td>178</td>\n",
       "      <td>165</td>\n",
       "      <td>0.2714</td>\n",
       "      <td>118.067236</td>\n",
       "      <td>85.933587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>duane_kupier_970</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.007669</td>\n",
       "      <td>0.802579</td>\n",
       "      <td>0.545245</td>\n",
       "      <td>0.405754</td>\n",
       "      <td>0.535276</td>\n",
       "      <td>0.526786</td>\n",
       "      <td>0.082822</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.299603</td>\n",
       "      <td>0.573620</td>\n",
       "      <td>L</td>\n",
       "      <td>183</td>\n",
       "      <td>175</td>\n",
       "      <td>0.2714</td>\n",
       "      <td>284.026542</td>\n",
       "      <td>280.422609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>norm_cash_969</td>\n",
       "      <td>0.576531</td>\n",
       "      <td>0.039666</td>\n",
       "      <td>0.856122</td>\n",
       "      <td>0.315762</td>\n",
       "      <td>0.508163</td>\n",
       "      <td>0.380480</td>\n",
       "      <td>0.568367</td>\n",
       "      <td>0.137787</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.505741</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.473382</td>\n",
       "      <td>L</td>\n",
       "      <td>183</td>\n",
       "      <td>185</td>\n",
       "      <td>0.2714</td>\n",
       "      <td>304.824128</td>\n",
       "      <td>295.144547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>garry_templeton_968</td>\n",
       "      <td>0.653045</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.203901</td>\n",
       "      <td>0.677083</td>\n",
       "      <td>0.327423</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.123522</td>\n",
       "      <td>0.568109</td>\n",
       "      <td>0.536052</td>\n",
       "      <td>0.349359</td>\n",
       "      <td>0.475768</td>\n",
       "      <td>L</td>\n",
       "      <td>180</td>\n",
       "      <td>175</td>\n",
       "      <td>0.2715</td>\n",
       "      <td>299.656371</td>\n",
       "      <td>278.869770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>rey_sanchez_967</td>\n",
       "      <td>0.395257</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.139328</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.418972</td>\n",
       "      <td>0.489216</td>\n",
       "      <td>0.411067</td>\n",
       "      <td>0.103922</td>\n",
       "      <td>0.309289</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.622530</td>\n",
       "      <td>0.719608</td>\n",
       "      <td>R</td>\n",
       "      <td>178</td>\n",
       "      <td>180</td>\n",
       "      <td>0.2715</td>\n",
       "      <td>80.848188</td>\n",
       "      <td>74.357691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ray_knight_966</td>\n",
       "      <td>0.362261</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>0.140127</td>\n",
       "      <td>0.331644</td>\n",
       "      <td>0.414013</td>\n",
       "      <td>0.405968</td>\n",
       "      <td>0.426752</td>\n",
       "      <td>0.083896</td>\n",
       "      <td>0.476115</td>\n",
       "      <td>0.539414</td>\n",
       "      <td>0.703025</td>\n",
       "      <td>0.524775</td>\n",
       "      <td>R</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>0.2715</td>\n",
       "      <td>71.051180</td>\n",
       "      <td>92.493525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>jerry_browne_965</td>\n",
       "      <td>0.375536</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.100858</td>\n",
       "      <td>0.402556</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.433706</td>\n",
       "      <td>0.326180</td>\n",
       "      <td>0.199681</td>\n",
       "      <td>0.408798</td>\n",
       "      <td>0.523962</td>\n",
       "      <td>0.615880</td>\n",
       "      <td>0.465655</td>\n",
       "      <td>R</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>0.2715</td>\n",
       "      <td>64.244199</td>\n",
       "      <td>88.567981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>barry_bonnell_964</td>\n",
       "      <td>0.480198</td>\n",
       "      <td>0.069322</td>\n",
       "      <td>0.129950</td>\n",
       "      <td>0.436578</td>\n",
       "      <td>0.483911</td>\n",
       "      <td>0.465339</td>\n",
       "      <td>0.408416</td>\n",
       "      <td>0.245575</td>\n",
       "      <td>0.410891</td>\n",
       "      <td>0.600295</td>\n",
       "      <td>0.674505</td>\n",
       "      <td>0.581858</td>\n",
       "      <td>R</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>0.2715</td>\n",
       "      <td>51.003254</td>\n",
       "      <td>86.399049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>leon_wagner_962</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.178302</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.620755</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.491509</td>\n",
       "      <td>0.492000</td>\n",
       "      <td>0.178302</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>0.546226</td>\n",
       "      <td>0.274000</td>\n",
       "      <td>0.535849</td>\n",
       "      <td>L</td>\n",
       "      <td>185</td>\n",
       "      <td>195</td>\n",
       "      <td>0.2716</td>\n",
       "      <td>254.910541</td>\n",
       "      <td>301.333228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>norm_siebern_961</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.131667</td>\n",
       "      <td>0.284335</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>0.055794</td>\n",
       "      <td>0.353333</td>\n",
       "      <td>0.477468</td>\n",
       "      <td>0.661667</td>\n",
       "      <td>0.463519</td>\n",
       "      <td>L</td>\n",
       "      <td>188</td>\n",
       "      <td>200</td>\n",
       "      <td>0.2716</td>\n",
       "      <td>68.831901</td>\n",
       "      <td>76.448749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ray_lankford_960</td>\n",
       "      <td>0.462413</td>\n",
       "      <td>0.013060</td>\n",
       "      <td>0.925699</td>\n",
       "      <td>0.285448</td>\n",
       "      <td>0.527098</td>\n",
       "      <td>0.404851</td>\n",
       "      <td>0.520105</td>\n",
       "      <td>0.133085</td>\n",
       "      <td>0.532343</td>\n",
       "      <td>0.674751</td>\n",
       "      <td>0.238636</td>\n",
       "      <td>0.608831</td>\n",
       "      <td>L</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>0.2716</td>\n",
       "      <td>312.870833</td>\n",
       "      <td>283.944193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>omar_vizquel_959</td>\n",
       "      <td>0.259649</td>\n",
       "      <td>0.039112</td>\n",
       "      <td>0.197368</td>\n",
       "      <td>0.418076</td>\n",
       "      <td>0.441228</td>\n",
       "      <td>0.447146</td>\n",
       "      <td>0.414035</td>\n",
       "      <td>0.225687</td>\n",
       "      <td>0.487719</td>\n",
       "      <td>0.554440</td>\n",
       "      <td>0.707018</td>\n",
       "      <td>0.492600</td>\n",
       "      <td>R</td>\n",
       "      <td>175</td>\n",
       "      <td>180</td>\n",
       "      <td>0.2718</td>\n",
       "      <td>87.465150</td>\n",
       "      <td>86.885136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>jeffrey_hammonds_958</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.087591</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.192822</td>\n",
       "      <td>0.249132</td>\n",
       "      <td>0.307786</td>\n",
       "      <td>0.308160</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0.365451</td>\n",
       "      <td>0.497567</td>\n",
       "      <td>0.637153</td>\n",
       "      <td>0.458637</td>\n",
       "      <td>R</td>\n",
       "      <td>183</td>\n",
       "      <td>195</td>\n",
       "      <td>0.2718</td>\n",
       "      <td>38.609616</td>\n",
       "      <td>90.322404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>orlando_cabrera_957</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>0.055833</td>\n",
       "      <td>0.227573</td>\n",
       "      <td>0.299167</td>\n",
       "      <td>0.305409</td>\n",
       "      <td>0.363333</td>\n",
       "      <td>0.097625</td>\n",
       "      <td>0.365000</td>\n",
       "      <td>0.542876</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.494723</td>\n",
       "      <td>R</td>\n",
       "      <td>178</td>\n",
       "      <td>195</td>\n",
       "      <td>0.2718</td>\n",
       "      <td>39.419077</td>\n",
       "      <td>78.945711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>adam_kennedy_956</td>\n",
       "      <td>0.412757</td>\n",
       "      <td>0.047423</td>\n",
       "      <td>0.722141</td>\n",
       "      <td>0.252062</td>\n",
       "      <td>0.550587</td>\n",
       "      <td>0.360309</td>\n",
       "      <td>0.563050</td>\n",
       "      <td>0.160309</td>\n",
       "      <td>0.586510</td>\n",
       "      <td>0.469588</td>\n",
       "      <td>0.372434</td>\n",
       "      <td>0.458247</td>\n",
       "      <td>L</td>\n",
       "      <td>180</td>\n",
       "      <td>195</td>\n",
       "      <td>0.2719</td>\n",
       "      <td>294.266678</td>\n",
       "      <td>277.370294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>dwight_evans_955</td>\n",
       "      <td>0.429365</td>\n",
       "      <td>0.139755</td>\n",
       "      <td>0.080159</td>\n",
       "      <td>0.328508</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.431514</td>\n",
       "      <td>0.384127</td>\n",
       "      <td>0.168151</td>\n",
       "      <td>0.363492</td>\n",
       "      <td>0.512249</td>\n",
       "      <td>0.606349</td>\n",
       "      <td>0.477171</td>\n",
       "      <td>R</td>\n",
       "      <td>188</td>\n",
       "      <td>180</td>\n",
       "      <td>0.2719</td>\n",
       "      <td>48.899300</td>\n",
       "      <td>78.349276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ken_camniniti_954</td>\n",
       "      <td>0.724359</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.895032</td>\n",
       "      <td>0.431057</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.447809</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.143686</td>\n",
       "      <td>0.625801</td>\n",
       "      <td>0.521907</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>0.471649</td>\n",
       "      <td>L</td>\n",
       "      <td>183</td>\n",
       "      <td>200</td>\n",
       "      <td>0.2719</td>\n",
       "      <td>288.094299</td>\n",
       "      <td>279.027108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>marquis_grissom_953</td>\n",
       "      <td>0.291379</td>\n",
       "      <td>0.045768</td>\n",
       "      <td>0.261207</td>\n",
       "      <td>0.391240</td>\n",
       "      <td>0.528448</td>\n",
       "      <td>0.477854</td>\n",
       "      <td>0.442241</td>\n",
       "      <td>0.242618</td>\n",
       "      <td>0.368103</td>\n",
       "      <td>0.551673</td>\n",
       "      <td>0.623276</td>\n",
       "      <td>0.549213</td>\n",
       "      <td>R</td>\n",
       "      <td>180</td>\n",
       "      <td>190</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>102.966445</td>\n",
       "      <td>75.958093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ivan_calderon_952</td>\n",
       "      <td>0.359259</td>\n",
       "      <td>0.046036</td>\n",
       "      <td>0.173148</td>\n",
       "      <td>0.223785</td>\n",
       "      <td>0.403704</td>\n",
       "      <td>0.337596</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.075448</td>\n",
       "      <td>0.401852</td>\n",
       "      <td>0.489130</td>\n",
       "      <td>0.702778</td>\n",
       "      <td>0.459719</td>\n",
       "      <td>R</td>\n",
       "      <td>185</td>\n",
       "      <td>220</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>69.956153</td>\n",
       "      <td>84.674430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>wally_westlake_951</td>\n",
       "      <td>0.292328</td>\n",
       "      <td>0.081132</td>\n",
       "      <td>0.072751</td>\n",
       "      <td>0.387736</td>\n",
       "      <td>0.498677</td>\n",
       "      <td>0.497170</td>\n",
       "      <td>0.421958</td>\n",
       "      <td>0.174528</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.828302</td>\n",
       "      <td>0.921958</td>\n",
       "      <td>0.781132</td>\n",
       "      <td>R</td>\n",
       "      <td>183</td>\n",
       "      <td>186</td>\n",
       "      <td>0.2721</td>\n",
       "      <td>68.800779</td>\n",
       "      <td>87.819976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>bobby_higginson_950</td>\n",
       "      <td>0.645186</td>\n",
       "      <td>0.032242</td>\n",
       "      <td>0.906832</td>\n",
       "      <td>0.410218</td>\n",
       "      <td>0.670807</td>\n",
       "      <td>0.473710</td>\n",
       "      <td>0.622671</td>\n",
       "      <td>0.230655</td>\n",
       "      <td>0.680901</td>\n",
       "      <td>0.543155</td>\n",
       "      <td>0.430124</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>L</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>0.2721</td>\n",
       "      <td>289.635663</td>\n",
       "      <td>290.319335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>marcel_ozuna-949</td>\n",
       "      <td>0.317308</td>\n",
       "      <td>0.075843</td>\n",
       "      <td>0.180556</td>\n",
       "      <td>0.452949</td>\n",
       "      <td>0.429487</td>\n",
       "      <td>0.525281</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>0.262640</td>\n",
       "      <td>0.344017</td>\n",
       "      <td>0.591994</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>R</td>\n",
       "      <td>185</td>\n",
       "      <td>225</td>\n",
       "      <td>0.2723</td>\n",
       "      <td>86.269866</td>\n",
       "      <td>66.875078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Player      T1_1      T1_2      T2_1      T2_2      T3_1  \\\n",
       "0       mike_marshall_999  0.500723  0.019169  0.096098  0.576677  0.379335   \n",
       "1     alfonso_soriano_998  0.526171  0.002045  0.055096  0.237219  0.292011   \n",
       "2           jody_reed_997  0.464928  0.004630  0.079137  0.461640  0.373201   \n",
       "3          kevin_bass_996  0.477839  0.020161  0.931440  0.307460  0.623269   \n",
       "4       jason_barlett_995  0.424769  0.003546  0.125000  0.348404  0.445602   \n",
       "5       bobby_thomson_994  0.479962  0.127743  0.229008  0.507837  0.478053   \n",
       "6        rube_oldring_993  0.702236  0.203125  0.239837  0.382812  0.434959   \n",
       "7         bill_spiers_992  0.421053  0.006925  0.862664  0.296399  0.702303   \n",
       "8      glenallen_hill_991  0.236891  0.006631  0.324906  0.289125  0.524345   \n",
       "9     terry_steinbach_990  0.298817  0.007229  0.139053  0.219880  0.323225   \n",
       "10          cory_hart_989  0.467470  0.035965  0.109639  0.359649  0.357831   \n",
       "11     tino_martiniez_988  0.640625  0.052500  0.835069  0.297000  0.605035   \n",
       "12       omar_infante_987  0.614621  0.113071  0.209386  0.195539  0.466606   \n",
       "13     milton_bradley_986  0.630117  0.035204  0.108187  0.335204  0.328947   \n",
       "14       mike_lansing_985  0.206422  0.051296  0.040520  0.427646  0.318807   \n",
       "15     kid_elberfield_984  0.097166  0.194981  0.680162  0.386100  0.859312   \n",
       "16        jorge_cantu_983  0.363497  0.053672  0.131135  0.368644  0.301380   \n",
       "17       bill_bradley_982  0.104839  0.107717  0.280914  0.481511  0.564516   \n",
       "18        erick_aybar_981  0.358859  0.102113  0.337838  0.467807  0.536787   \n",
       "19          roy_white_980  0.425856  0.046537  0.859316  0.404762  0.546578   \n",
       "20           tom_herr_979  0.673137  0.008333  0.802795  0.371795  0.462733   \n",
       "21   christian_guzman_978  0.058673  0.011798  0.323129  0.416854  0.561224   \n",
       "22    edddie_matthews_977  0.522177  0.079521  0.898522  0.526144  0.452285   \n",
       "23       steve_finlay_976  0.509291  0.008157  0.866554  0.245202  0.590372   \n",
       "24       carl_everett_975  0.466454  0.047423  0.070288  0.322165  0.269968   \n",
       "25      denny_walling_974  0.659167  0.015504  0.810000  0.438630  0.576667   \n",
       "26         joe_morgan_973  0.805451  0.027385  0.789474  0.545936  0.501880   \n",
       "27  doug_mientkiewicz_972  0.803381  0.007979  0.626335  0.391622  0.389680   \n",
       "28      sixto_lezcano_971  0.262097  0.012987  0.232258  0.482955  0.374194   \n",
       "29       duane_kupier_970  0.682540  0.007669  0.802579  0.545245  0.405754   \n",
       "30          norm_cash_969  0.576531  0.039666  0.856122  0.315762  0.508163   \n",
       "31    garry_templeton_968  0.653045  0.007092  0.935897  0.203901  0.677083   \n",
       "32        rey_sanchez_967  0.395257  0.004902  0.139328  0.338235  0.418972   \n",
       "33         ray_knight_966  0.362261  0.003941  0.140127  0.331644  0.414013   \n",
       "34       jerry_browne_965  0.375536  0.004792  0.100858  0.402556  0.300429   \n",
       "35      barry_bonnell_964  0.480198  0.069322  0.129950  0.436578  0.483911   \n",
       "36        leon_wagner_962  0.868000  0.178302  0.512000  0.620755  0.218000   \n",
       "37       norm_siebern_961  0.270000  0.004292  0.131667  0.284335  0.455000   \n",
       "38       ray_lankford_960  0.462413  0.013060  0.925699  0.285448  0.527098   \n",
       "39       omar_vizquel_959  0.259649  0.039112  0.197368  0.418076  0.441228   \n",
       "40   jeffrey_hammonds_958  0.583333  0.087591  0.031250  0.192822  0.249132   \n",
       "41    orlando_cabrera_957  0.610000  0.007256  0.055833  0.227573  0.299167   \n",
       "42       adam_kennedy_956  0.412757  0.047423  0.722141  0.252062  0.550587   \n",
       "43       dwight_evans_955  0.429365  0.139755  0.080159  0.328508  0.355556   \n",
       "44      ken_camniniti_954  0.724359  0.005799  0.895032  0.431057  0.641026   \n",
       "45    marquis_grissom_953  0.291379  0.045768  0.261207  0.391240  0.528448   \n",
       "46      ivan_calderon_952  0.359259  0.046036  0.173148  0.223785  0.403704   \n",
       "47     wally_westlake_951  0.292328  0.081132  0.072751  0.387736  0.498677   \n",
       "48    bobby_higginson_950  0.645186  0.032242  0.906832  0.410218  0.670807   \n",
       "49       marcel_ozuna-949  0.317308  0.075843  0.180556  0.452949  0.429487   \n",
       "\n",
       "        T3_2      H1_1      H1_2      H2_1      H2_2      H3_1      H3_2 hand  \\\n",
       "0   0.605431  0.413295  0.137380  0.497110  0.715655  0.734827  0.645367    R   \n",
       "1   0.388037  0.365014  0.171779  0.436639  0.527607  0.630165  0.514315    R   \n",
       "2   0.490079  0.438849  0.112434  0.566547  0.713624  0.872302  0.660053    R   \n",
       "3   0.403226  0.584488  0.099798  0.493075  0.564516  0.198061  0.521169    L   \n",
       "4   0.480496  0.493056  0.097518  0.400463  0.738475  0.788194  0.731383    R   \n",
       "5   0.542320  0.485687  0.167712  0.458969  0.721787  0.743321  0.709248    R   \n",
       "6   0.414062  0.526423  0.213778  0.470528  0.566051  0.706301  0.529119    R   \n",
       "7   0.351801  0.661184  0.047784  0.541118  0.468837  0.318257  0.409280    L   \n",
       "8   0.322944  0.432584  0.094164  0.365169  0.415119  0.571161  0.391910    R   \n",
       "9   0.343373  0.378698  0.056024  0.434911  0.490964  0.695266  0.444578    R   \n",
       "10  0.419737  0.392771  0.160965  0.362651  0.535088  0.618675  0.501316    R   \n",
       "11  0.391000  0.625868  0.178000  0.642361  0.542000  0.392361  0.517500    L   \n",
       "12  0.342842  0.405235  0.103734  0.276173  0.488589  0.560469  0.478734    R   \n",
       "13  0.442857  0.371345  0.152551  0.423977  0.578571  0.627193  0.554592    R   \n",
       "14  0.449784  0.308104  0.205724  0.337156  0.541037  0.573394  0.516199    R   \n",
       "15  0.398649  0.532389  0.146236  0.408907  0.512548  0.707490  0.505792    R   \n",
       "16  0.474576  0.302147  0.289077  0.319785  0.590866  0.537577  0.572976    R   \n",
       "17  0.459807  0.565860  0.144695  0.366935  0.504823  0.681452  0.464630    R   \n",
       "18  0.504527  0.445946  0.231891  0.353604  0.551308  0.617868  0.527163    R   \n",
       "19  0.439394  0.531369  0.121212  0.518061  0.482684  0.258555  0.471861    L   \n",
       "20  0.476282  0.479814  0.115385  0.496894  0.721154  0.159161  0.679487    L   \n",
       "21  0.447191  0.447279  0.136517  0.250000  0.553371  0.582483  0.547191    R   \n",
       "22  0.587691  0.561828  0.104031  0.581989  0.948257  0.122984  0.921024    L   \n",
       "23  0.345010  0.628378  0.156910  0.662162  0.533109  0.383446  0.499520    L   \n",
       "24  0.409278  0.367412  0.218041  0.320288  0.542268  0.575080  0.512887    R   \n",
       "25  0.486434  0.600000  0.167313  0.625000  0.544574  0.408333  0.524548    L   \n",
       "26  0.573322  0.650376  0.126325  0.610902  0.648410  0.333647  0.616608    L   \n",
       "27  0.369016  0.512456  0.095745  0.599644  0.515957  0.341637  0.511303    L   \n",
       "28  0.570617  0.411290  0.322240  0.458065  0.763799  0.649194  0.729708    R   \n",
       "29  0.535276  0.526786  0.082822  0.603175  0.582822  0.299603  0.573620    L   \n",
       "30  0.380480  0.568367  0.137787  0.704082  0.505741  0.326531  0.473382    L   \n",
       "31  0.327423  0.615385  0.123522  0.568109  0.536052  0.349359  0.475768    L   \n",
       "32  0.489216  0.411067  0.103922  0.309289  0.756863  0.622530  0.719608    R   \n",
       "33  0.405968  0.426752  0.083896  0.476115  0.539414  0.703025  0.524775    R   \n",
       "34  0.433706  0.326180  0.199681  0.408798  0.523962  0.615880  0.465655    R   \n",
       "35  0.465339  0.408416  0.245575  0.410891  0.600295  0.674505  0.581858    R   \n",
       "36  0.491509  0.492000  0.178302  0.704000  0.546226  0.274000  0.535849    L   \n",
       "37  0.313305  0.435000  0.055794  0.353333  0.477468  0.661667  0.463519    L   \n",
       "38  0.404851  0.520105  0.133085  0.532343  0.674751  0.238636  0.608831    L   \n",
       "39  0.447146  0.414035  0.225687  0.487719  0.554440  0.707018  0.492600    R   \n",
       "40  0.307786  0.308160  0.113139  0.365451  0.497567  0.637153  0.458637    R   \n",
       "41  0.305409  0.363333  0.097625  0.365000  0.542876  0.606667  0.494723    R   \n",
       "42  0.360309  0.563050  0.160309  0.586510  0.469588  0.372434  0.458247    L   \n",
       "43  0.431514  0.384127  0.168151  0.363492  0.512249  0.606349  0.477171    R   \n",
       "44  0.447809  0.653846  0.143686  0.625801  0.521907  0.412660  0.471649    L   \n",
       "45  0.477854  0.442241  0.242618  0.368103  0.551673  0.623276  0.549213    R   \n",
       "46  0.337596  0.400000  0.075448  0.401852  0.489130  0.702778  0.459719    R   \n",
       "47  0.497170  0.421958  0.174528  0.464286  0.828302  0.921958  0.781132    R   \n",
       "48  0.473710  0.622671  0.230655  0.680901  0.543155  0.430124  0.500000    L   \n",
       "49  0.525281  0.442308  0.262640  0.344017  0.591994  0.602564  0.562500    R   \n",
       "\n",
       "    height  weight      BA      Angle1      Angle2  \n",
       "0      196     215  0.2702   59.825581   81.775144  \n",
       "1      185     195  0.2703   59.010142   97.451951  \n",
       "2      175     170  0.2703   55.354085   92.054036  \n",
       "3      183     183  0.2703  310.387953  267.230408  \n",
       "4      183     190  0.2703   71.393355   80.732005  \n",
       "5      188     180  0.2704   64.448638   84.714362  \n",
       "6      178     186  0.2704   30.334995   72.081471  \n",
       "7      188     190  0.2705  307.696180  269.046147  \n",
       "8      190     210  0.2705  116.929296   71.709378  \n",
       "9      185     195  0.2706   86.925652   87.262191  \n",
       "10     198     240  0.2706   55.741223   77.882668  \n",
       "11     188     205  0.2707  286.267591  278.191436  \n",
       "12     180     195  0.2707   41.301599   69.475666  \n",
       "13     183     215  0.2707   55.885895   90.313188  \n",
       "14     183     175  0.2708   70.759589   88.949811  \n",
       "15     170     158  0.2708  165.856589   70.075085  \n",
       "16     190     205  0.2708   85.474184   88.648955  \n",
       "17     183     185  0.2709  110.846394   53.802409  \n",
       "18     178     195  0.2709   97.167506   68.655212  \n",
       "19     178     160  0.2711  314.109523  270.279747  \n",
       "20     183     175  0.2711  272.552841  278.648249  \n",
       "21     183     180  0.2711  130.401264   63.608969  \n",
       "22     185     190  0.2712  302.266080  274.763431  \n",
       "23     188     175  0.2712  306.566525  282.003365  \n",
       "24     183     181  0.2712   58.311257   75.152455  \n",
       "25     183     180  0.2713  278.041549  279.071988  \n",
       "26     170     160  0.2713  262.795665  272.219591  \n",
       "27     188     195  0.2714  250.683832  282.755143  \n",
       "28     178     165  0.2714  118.067236   85.933587  \n",
       "29     183     175  0.2714  284.026542  280.422609  \n",
       "30     183     185  0.2714  304.824128  295.144547  \n",
       "31     180     175  0.2715  299.656371  278.869770  \n",
       "32     178     180  0.2715   80.848188   74.357691  \n",
       "33     185     185  0.2715   71.051180   92.493525  \n",
       "34     185     185  0.2715   64.244199   88.567981  \n",
       "35     190     190  0.2715   51.003254   86.399049  \n",
       "36     185     195  0.2716  254.910541  301.333228  \n",
       "37     188     200  0.2716   68.831901   76.448749  \n",
       "38     180     180  0.2716  312.870833  283.944193  \n",
       "39     175     180  0.2718   87.465150   86.885136  \n",
       "40     183     195  0.2718   38.609616   90.322404  \n",
       "41     178     195  0.2718   39.419077   78.945711  \n",
       "42     180     195  0.2719  294.266678  277.370294  \n",
       "43     188     180  0.2719   48.899300   78.349276  \n",
       "44     183     200  0.2719  288.094299  279.027108  \n",
       "45     180     190  0.2720  102.966445   75.958093  \n",
       "46     185     220  0.2720   69.956153   84.674430  \n",
       "47     183     186  0.2721   68.800779   87.819976  \n",
       "48     180     180  0.2721  289.635663  290.319335  \n",
       "49     185     225  0.2723   86.269866   66.875078  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Angle1    float64\n",
       "Angle2    float64\n",
       "height      int64\n",
       "weight      int64\n",
       "hand       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df[['Angle1', 'Angle2', 'height', 'weight','hand']]\n",
    "new_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= new_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df[['BA']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2702],\n",
       "       [0.2703],\n",
       "       [0.2703],\n",
       "       [0.2703],\n",
       "       [0.2703],\n",
       "       [0.2704],\n",
       "       [0.2704],\n",
       "       [0.2705],\n",
       "       [0.2705],\n",
       "       [0.2706],\n",
       "       [0.2706],\n",
       "       [0.2707],\n",
       "       [0.2707],\n",
       "       [0.2707],\n",
       "       [0.2708],\n",
       "       [0.2708],\n",
       "       [0.2708],\n",
       "       [0.2709],\n",
       "       [0.2709],\n",
       "       [0.2711],\n",
       "       [0.2711],\n",
       "       [0.2711],\n",
       "       [0.2712],\n",
       "       [0.2712],\n",
       "       [0.2712],\n",
       "       [0.2713],\n",
       "       [0.2713],\n",
       "       [0.2714],\n",
       "       [0.2714],\n",
       "       [0.2714],\n",
       "       [0.2714],\n",
       "       [0.2715],\n",
       "       [0.2715],\n",
       "       [0.2715],\n",
       "       [0.2715],\n",
       "       [0.2715],\n",
       "       [0.2716],\n",
       "       [0.2716],\n",
       "       [0.2716],\n",
       "       [0.2718],\n",
       "       [0.2718],\n",
       "       [0.2718],\n",
       "       [0.2719],\n",
       "       [0.2719],\n",
       "       [0.2719],\n",
       "       [0.272 ],\n",
       "       [0.272 ],\n",
       "       [0.2721],\n",
       "       [0.2721],\n",
       "       [0.2723]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(10, kernel_initializer=\"he_normal\", activation=\"relu\"),\n",
    "    #keras.layers.PReLU(),\n",
    "    keras.layers.Dense(10, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-c26734a733f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m                  \u001b[0;31m#   validation_data=(X_valid, y_valid))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    381\u001b[0m     dataset = dataset_ops.DatasetV2.zip((\n\u001b[1;32m    382\u001b[0m         \u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m     ))\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensors\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    564\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     \"\"\"\n\u001b[0;32m--> 566\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   2763\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2764\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensors()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2765\u001b[0;31m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2766\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2767\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m           normalized_components.append(\n\u001b[0;32m--> 113\u001b[0;31m               ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001b[0m\u001b[1;32m    114\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \"\"\"\n\u001b[1;32m    257\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 258\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    264\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10)\n",
    "                 #   validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
