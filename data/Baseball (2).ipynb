{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junweiluo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/junweiluo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/junweiluo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/junweiluo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/junweiluo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/junweiluo/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Input\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvpath = Path('database.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csvpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:149,:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>T1_1</th>\n",
       "      <th>T1_2</th>\n",
       "      <th>T2_1</th>\n",
       "      <th>T2_2</th>\n",
       "      <th>T3_1</th>\n",
       "      <th>T3_2</th>\n",
       "      <th>H1_1</th>\n",
       "      <th>H1_2</th>\n",
       "      <th>H2_1</th>\n",
       "      <th>...</th>\n",
       "      <th>RBI</th>\n",
       "      <th>SB</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>OPS</th>\n",
       "      <th>OPS+</th>\n",
       "      <th>BA</th>\n",
       "      <th>Top</th>\n",
       "      <th>Middle</th>\n",
       "      <th>Bottom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ty_Cobb</td>\n",
       "      <td>0.949931</td>\n",
       "      <td>0.122283</td>\n",
       "      <td>0.900549</td>\n",
       "      <td>0.374457</td>\n",
       "      <td>0.664609</td>\n",
       "      <td>0.321739</td>\n",
       "      <td>0.679010</td>\n",
       "      <td>0.018480</td>\n",
       "      <td>0.698220</td>\n",
       "      <td>...</td>\n",
       "      <td>1944</td>\n",
       "      <td>897</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.944</td>\n",
       "      <td>168</td>\n",
       "      <td>0.3660</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Babe_Ruth</td>\n",
       "      <td>0.631318</td>\n",
       "      <td>0.159712</td>\n",
       "      <td>0.805748</td>\n",
       "      <td>0.376259</td>\n",
       "      <td>0.677899</td>\n",
       "      <td>0.395683</td>\n",
       "      <td>0.628345</td>\n",
       "      <td>0.233813</td>\n",
       "      <td>0.682854</td>\n",
       "      <td>...</td>\n",
       "      <td>2214</td>\n",
       "      <td>123</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.690</td>\n",
       "      <td>1.164</td>\n",
       "      <td>206</td>\n",
       "      <td>0.3420</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lou_Gehrig</td>\n",
       "      <td>0.613402</td>\n",
       "      <td>0.046107</td>\n",
       "      <td>0.787371</td>\n",
       "      <td>0.425205</td>\n",
       "      <td>0.574742</td>\n",
       "      <td>0.448770</td>\n",
       "      <td>0.519330</td>\n",
       "      <td>0.218240</td>\n",
       "      <td>0.640460</td>\n",
       "      <td>...</td>\n",
       "      <td>1995</td>\n",
       "      <td>102</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.632</td>\n",
       "      <td>1.080</td>\n",
       "      <td>179</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tony_Gwynn</td>\n",
       "      <td>0.519866</td>\n",
       "      <td>0.141333</td>\n",
       "      <td>0.671135</td>\n",
       "      <td>0.391333</td>\n",
       "      <td>0.506462</td>\n",
       "      <td>0.480667</td>\n",
       "      <td>0.520820</td>\n",
       "      <td>0.282670</td>\n",
       "      <td>0.617520</td>\n",
       "      <td>...</td>\n",
       "      <td>1138</td>\n",
       "      <td>319</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.847</td>\n",
       "      <td>132</td>\n",
       "      <td>0.3380</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Al_Simmons</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.270202</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.460784</td>\n",
       "      <td>0.388890</td>\n",
       "      <td>0.133330</td>\n",
       "      <td>0.419190</td>\n",
       "      <td>...</td>\n",
       "      <td>1828</td>\n",
       "      <td>88</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.915</td>\n",
       "      <td>133</td>\n",
       "      <td>0.3340</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>marquis_grissom_953</td>\n",
       "      <td>0.291379</td>\n",
       "      <td>0.045768</td>\n",
       "      <td>0.261207</td>\n",
       "      <td>0.391240</td>\n",
       "      <td>0.528448</td>\n",
       "      <td>0.477854</td>\n",
       "      <td>0.442240</td>\n",
       "      <td>0.242620</td>\n",
       "      <td>0.368100</td>\n",
       "      <td>...</td>\n",
       "      <td>967</td>\n",
       "      <td>429</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.732</td>\n",
       "      <td>92</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>ivan_calderon_952</td>\n",
       "      <td>0.359259</td>\n",
       "      <td>0.046036</td>\n",
       "      <td>0.173148</td>\n",
       "      <td>0.223785</td>\n",
       "      <td>0.403704</td>\n",
       "      <td>0.337596</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.075450</td>\n",
       "      <td>0.401850</td>\n",
       "      <td>...</td>\n",
       "      <td>444</td>\n",
       "      <td>97</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.775</td>\n",
       "      <td>113</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>wally_westlake_951</td>\n",
       "      <td>0.292328</td>\n",
       "      <td>0.081132</td>\n",
       "      <td>0.072751</td>\n",
       "      <td>0.387736</td>\n",
       "      <td>0.498677</td>\n",
       "      <td>0.497170</td>\n",
       "      <td>0.421960</td>\n",
       "      <td>0.174530</td>\n",
       "      <td>0.464290</td>\n",
       "      <td>...</td>\n",
       "      <td>539</td>\n",
       "      <td>19</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.795</td>\n",
       "      <td>111</td>\n",
       "      <td>0.2721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>bobby_higginson_950</td>\n",
       "      <td>0.645186</td>\n",
       "      <td>0.032242</td>\n",
       "      <td>0.906832</td>\n",
       "      <td>0.410218</td>\n",
       "      <td>0.670807</td>\n",
       "      <td>0.473710</td>\n",
       "      <td>0.622670</td>\n",
       "      <td>0.230660</td>\n",
       "      <td>0.680900</td>\n",
       "      <td>...</td>\n",
       "      <td>709</td>\n",
       "      <td>91</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.813</td>\n",
       "      <td>113</td>\n",
       "      <td>0.2721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>marcel_ozuna-949</td>\n",
       "      <td>0.317308</td>\n",
       "      <td>0.075843</td>\n",
       "      <td>0.180556</td>\n",
       "      <td>0.452949</td>\n",
       "      <td>0.429487</td>\n",
       "      <td>0.525281</td>\n",
       "      <td>0.442310</td>\n",
       "      <td>0.262640</td>\n",
       "      <td>0.344020</td>\n",
       "      <td>...</td>\n",
       "      <td>591</td>\n",
       "      <td>115</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.718</td>\n",
       "      <td>93</td>\n",
       "      <td>0.2723</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Player      T1_1      T1_2      T2_1      T2_2      T3_1  \\\n",
       "0                Ty_Cobb  0.949931  0.122283  0.900549  0.374457  0.664609   \n",
       "1              Babe_Ruth  0.631318  0.159712  0.805748  0.376259  0.677899   \n",
       "2             Lou_Gehrig  0.613402  0.046107  0.787371  0.425205  0.574742   \n",
       "3             Tony_Gwynn  0.519866  0.141333  0.671135  0.391333  0.506462   \n",
       "4             Al_Simmons  0.353535  0.062745  0.270202  0.447059  0.505051   \n",
       "..                   ...       ...       ...       ...       ...       ...   \n",
       "144  marquis_grissom_953  0.291379  0.045768  0.261207  0.391240  0.528448   \n",
       "145    ivan_calderon_952  0.359259  0.046036  0.173148  0.223785  0.403704   \n",
       "146   wally_westlake_951  0.292328  0.081132  0.072751  0.387736  0.498677   \n",
       "147  bobby_higginson_950  0.645186  0.032242  0.906832  0.410218  0.670807   \n",
       "148     marcel_ozuna-949  0.317308  0.075843  0.180556  0.452949  0.429487   \n",
       "\n",
       "         T3_2      H1_1      H1_2      H2_1  ...   RBI   SB    OBP    SLG  \\\n",
       "0    0.321739  0.679010  0.018480  0.698220  ...  1944  897  0.433  0.512   \n",
       "1    0.395683  0.628345  0.233813  0.682854  ...  2214  123  0.474  0.690   \n",
       "2    0.448770  0.519330  0.218240  0.640460  ...  1995  102  0.447  0.632   \n",
       "3    0.480667  0.520820  0.282670  0.617520  ...  1138  319  0.388  0.459   \n",
       "4    0.460784  0.388890  0.133330  0.419190  ...  1828   88  0.380  0.535   \n",
       "..        ...       ...       ...       ...  ...   ...  ...    ...    ...   \n",
       "144  0.477854  0.442240  0.242620  0.368100  ...   967  429  0.318  0.415   \n",
       "145  0.337596  0.400000  0.075450  0.401850  ...   444   97  0.333  0.442   \n",
       "146  0.497170  0.421960  0.174530  0.464290  ...   539   19  0.345  0.450   \n",
       "147  0.473710  0.622670  0.230660  0.680900  ...   709   91  0.358  0.455   \n",
       "148  0.525281  0.442310  0.262640  0.344020  ...   591  115  0.332  0.386   \n",
       "\n",
       "       OPS  OPS+      BA  Top  Middle  Bottom  \n",
       "0    0.944   168  0.3660    1       0       0  \n",
       "1    1.164   206  0.3420    1       0       0  \n",
       "2    1.080   179  0.3400    1       0       0  \n",
       "3    0.847   132  0.3380    1       0       0  \n",
       "4    0.915   133  0.3340    1       0       0  \n",
       "..     ...   ...     ...  ...     ...     ...  \n",
       "144  0.732    92  0.2720    0       0       1  \n",
       "145  0.775   113  0.2720    0       0       1  \n",
       "146  0.795   111  0.2721    0       0       1  \n",
       "147  0.813   113  0.2721    0       0       1  \n",
       "148  0.718    93  0.2723    0       0       1  \n",
       "\n",
       "[149 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTier(Top, Middle, Bottom):\n",
    "    if Top ==1:\n",
    "        Tier = 0\n",
    "    elif Middle==1:\n",
    "        Tier = 1\n",
    "    else:\n",
    "        Tier = 2\n",
    "    return Tier\n",
    "\n",
    "\n",
    "df['tier'] = df.apply(lambda x: getTier(x['Top'], x['Middle'], x['Bottom']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAngle(a, b, c, d):\n",
    "    ang = math.degrees(math.atan2(c[1]-b[1], c[0]-b[0]) - math.atan2(a[1]-b[1], a[0]-b[0]))\n",
    "    if ang < 0:\n",
    "        ang += 360\n",
    "    if d == 1:\n",
    "        ang = 360 - ang\n",
    "    return ang\n",
    "\n",
    "df['Angle1'] = df.apply(lambda x: getAngle((x['T1_1'],x['T1_2']),(x['T2_1'],x['T2_2']),(x['T3_1'],x['T3_2']),x['hand']),axis=1)\n",
    "df['Angle2'] = df.apply(lambda x: getAngle((x['H1_1'],x['H1_2']),(x['H2_1'],x['H2_2']),(x['H3_1'],x['H3_2']),x['hand']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df = df[['Angle1', 'Angle2','hand', 'height','weight','AB','H','HR','R','RBI','SB','OBP','SLG','OPS','OPS+']]\n",
    "new_df = df[['Angle1', 'Angle2','hand', 'height','weight','HR','R','RBI','SB','OBP','SLG','OPS','OPS+']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= new_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['BA']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[['tier']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_transformed = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid, Y_train, Y_valid = train_test_split(X_transformed, \n",
    "                                                    y, Y,\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(41)\n",
    "np.random.seed(41)\n",
    "\n",
    "input = keras.layers.Input(shape=[13], name=\"input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "output = keras.layers.Dense(3, activation='softmax',name=\"output\")(hidden2)\n",
    "aux_output = keras.layers.Dense(1, name='aux_output')(hidden2)\n",
    "model = keras.models.Model(inputs=[input], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 13)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30)           420         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30)           930         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 3)            93          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "aux_output (Dense)              (None, 1)            31          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,474\n",
      "Trainable params: 1,474\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = ['sparse_categorical_crossentropy','mean_squared_error'], \n",
    "              optimizer='adam', loss_weights=[0.5,0.5], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 111 samples\n",
      "Epoch 1/50\n",
      "111/111 [==============================] - 0s 4ms/sample - loss: 0.7837 - output_loss: 1.1246 - aux_output_loss: 0.4341 - output_accuracy: 0.3514 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "111/111 [==============================] - 0s 109us/sample - loss: 0.6815 - output_loss: 1.0953 - aux_output_loss: 0.2543 - output_accuracy: 0.3964 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "111/111 [==============================] - 0s 123us/sample - loss: 0.6239 - output_loss: 1.0923 - aux_output_loss: 0.1531 - output_accuracy: 0.4505 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "111/111 [==============================] - 0s 119us/sample - loss: 0.5889 - output_loss: 1.0725 - aux_output_loss: 0.0930 - output_accuracy: 0.4505 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "111/111 [==============================] - 0s 154us/sample - loss: 0.5688 - output_loss: 1.0815 - aux_output_loss: 0.0747 - output_accuracy: 0.4955 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "111/111 [==============================] - 0s 219us/sample - loss: 0.5568 - output_loss: 1.0613 - aux_output_loss: 0.0621 - output_accuracy: 0.4865 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "111/111 [==============================] - 0s 160us/sample - loss: 0.5458 - output_loss: 1.0304 - aux_output_loss: 0.0590 - output_accuracy: 0.5135 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "111/111 [==============================] - 0s 139us/sample - loss: 0.5349 - output_loss: 1.0280 - aux_output_loss: 0.0521 - output_accuracy: 0.5225 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "111/111 [==============================] - 0s 122us/sample - loss: 0.5241 - output_loss: 1.0051 - aux_output_loss: 0.0476 - output_accuracy: 0.5315 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "111/111 [==============================] - 0s 156us/sample - loss: 0.5145 - output_loss: 0.9950 - aux_output_loss: 0.0407 - output_accuracy: 0.5405 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "111/111 [==============================] - 0s 112us/sample - loss: 0.5065 - output_loss: 0.9787 - aux_output_loss: 0.0369 - output_accuracy: 0.5586 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "111/111 [==============================] - 0s 156us/sample - loss: 0.4990 - output_loss: 0.9565 - aux_output_loss: 0.0382 - output_accuracy: 0.5676 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "111/111 [==============================] - 0s 127us/sample - loss: 0.4921 - output_loss: 0.9365 - aux_output_loss: 0.0401 - output_accuracy: 0.5586 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "111/111 [==============================] - 0s 109us/sample - loss: 0.4854 - output_loss: 0.9358 - aux_output_loss: 0.0346 - output_accuracy: 0.5766 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "111/111 [==============================] - 0s 98us/sample - loss: 0.4779 - output_loss: 0.9240 - aux_output_loss: 0.0354 - output_accuracy: 0.5676 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "111/111 [==============================] - 0s 77us/sample - loss: 0.4711 - output_loss: 0.9216 - aux_output_loss: 0.0294 - output_accuracy: 0.5676 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "111/111 [==============================] - 0s 114us/sample - loss: 0.4642 - output_loss: 0.9141 - aux_output_loss: 0.0296 - output_accuracy: 0.5856 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "111/111 [==============================] - 0s 86us/sample - loss: 0.4575 - output_loss: 0.8875 - aux_output_loss: 0.0273 - output_accuracy: 0.5946 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "111/111 [==============================] - 0s 95us/sample - loss: 0.4512 - output_loss: 0.8804 - aux_output_loss: 0.0237 - output_accuracy: 0.6036 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "111/111 [==============================] - 0s 108us/sample - loss: 0.4448 - output_loss: 0.8781 - aux_output_loss: 0.0226 - output_accuracy: 0.6036 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "111/111 [==============================] - 0s 116us/sample - loss: 0.4385 - output_loss: 0.8746 - aux_output_loss: 0.0238 - output_accuracy: 0.6126 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "111/111 [==============================] - 0s 99us/sample - loss: 0.4325 - output_loss: 0.8339 - aux_output_loss: 0.0215 - output_accuracy: 0.6126 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "111/111 [==============================] - 0s 87us/sample - loss: 0.4263 - output_loss: 0.8065 - aux_output_loss: 0.0210 - output_accuracy: 0.6216 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "111/111 [==============================] - 0s 81us/sample - loss: 0.4202 - output_loss: 0.8201 - aux_output_loss: 0.0207 - output_accuracy: 0.6306 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "111/111 [==============================] - 0s 95us/sample - loss: 0.4143 - output_loss: 0.7924 - aux_output_loss: 0.0201 - output_accuracy: 0.6396 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "111/111 [==============================] - 0s 86us/sample - loss: 0.4090 - output_loss: 0.8158 - aux_output_loss: 0.0187 - output_accuracy: 0.6306 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "111/111 [==============================] - 0s 99us/sample - loss: 0.4032 - output_loss: 0.7807 - aux_output_loss: 0.0187 - output_accuracy: 0.6396 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "111/111 [==============================] - 0s 75us/sample - loss: 0.3976 - output_loss: 0.7708 - aux_output_loss: 0.0191 - output_accuracy: 0.6486 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "111/111 [==============================] - 0s 71us/sample - loss: 0.3922 - output_loss: 0.7537 - aux_output_loss: 0.0179 - output_accuracy: 0.6486 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "111/111 [==============================] - 0s 81us/sample - loss: 0.3868 - output_loss: 0.7489 - aux_output_loss: 0.0172 - output_accuracy: 0.6486 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "111/111 [==============================] - 0s 75us/sample - loss: 0.3818 - output_loss: 0.7455 - aux_output_loss: 0.0163 - output_accuracy: 0.6486 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "111/111 [==============================] - 0s 86us/sample - loss: 0.3768 - output_loss: 0.7419 - aux_output_loss: 0.0177 - output_accuracy: 0.6577 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "111/111 [==============================] - 0s 144us/sample - loss: 0.3720 - output_loss: 0.7231 - aux_output_loss: 0.0161 - output_accuracy: 0.6667 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "111/111 [==============================] - 0s 103us/sample - loss: 0.3671 - output_loss: 0.7054 - aux_output_loss: 0.0163 - output_accuracy: 0.6757 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "111/111 [==============================] - 0s 74us/sample - loss: 0.3627 - output_loss: 0.7295 - aux_output_loss: 0.0148 - output_accuracy: 0.6937 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "111/111 [==============================] - 0s 92us/sample - loss: 0.3580 - output_loss: 0.6925 - aux_output_loss: 0.0156 - output_accuracy: 0.7027 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "111/111 [==============================] - 0s 102us/sample - loss: 0.3536 - output_loss: 0.6974 - aux_output_loss: 0.0150 - output_accuracy: 0.7207 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "111/111 [==============================] - 0s 97us/sample - loss: 0.3490 - output_loss: 0.6797 - aux_output_loss: 0.0146 - output_accuracy: 0.7387 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "111/111 [==============================] - 0s 96us/sample - loss: 0.3449 - output_loss: 0.6596 - aux_output_loss: 0.0141 - output_accuracy: 0.7477 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "111/111 [==============================] - 0s 79us/sample - loss: 0.3408 - output_loss: 0.7047 - aux_output_loss: 0.0143 - output_accuracy: 0.7568 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "111/111 [==============================] - 0s 79us/sample - loss: 0.3365 - output_loss: 0.6446 - aux_output_loss: 0.0130 - output_accuracy: 0.7658 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "111/111 [==============================] - 0s 90us/sample - loss: 0.3328 - output_loss: 0.6449 - aux_output_loss: 0.0128 - output_accuracy: 0.7658 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "111/111 [==============================] - 0s 80us/sample - loss: 0.3290 - output_loss: 0.6631 - aux_output_loss: 0.0139 - output_accuracy: 0.7568 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "111/111 [==============================] - 0s 88us/sample - loss: 0.3253 - output_loss: 0.6177 - aux_output_loss: 0.0138 - output_accuracy: 0.7658 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "111/111 [==============================] - 0s 90us/sample - loss: 0.3215 - output_loss: 0.6584 - aux_output_loss: 0.0121 - output_accuracy: 0.7658 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "111/111 [==============================] - 0s 86us/sample - loss: 0.3182 - output_loss: 0.6119 - aux_output_loss: 0.0125 - output_accuracy: 0.7748 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "111/111 [==============================] - 0s 83us/sample - loss: 0.3143 - output_loss: 0.6166 - aux_output_loss: 0.0122 - output_accuracy: 0.7748 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "111/111 [==============================] - 0s 91us/sample - loss: 0.3108 - output_loss: 0.5982 - aux_output_loss: 0.0113 - output_accuracy: 0.7748 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "111/111 [==============================] - 0s 90us/sample - loss: 0.3075 - output_loss: 0.5887 - aux_output_loss: 0.0113 - output_accuracy: 0.7748 - aux_output_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "111/111 [==============================] - 0s 85us/sample - loss: 0.3045 - output_loss: 0.6098 - aux_output_loss: 0.0120 - output_accuracy: 0.7838 - aux_output_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, (Y_train,y_train), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 3ms/sample - loss: 0.4174 - output_loss: 0.8931 - aux_output_loss: 0.0231 - output_accuracy: 0.6579 - aux_output_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "total_loss = model.evaluate(X_valid, [Y_valid, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
